<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 17 Correlation, Causation, and LM | PPLS PhD Training Workshop: Statistics and R</title>
  <meta name="description" content="This is the main page of the course and contains a course overview, schedule and learning outcomes.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 17 Correlation, Causation, and LM | PPLS PhD Training Workshop: Statistics and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the main page of the course and contains a course overview, schedule and learning outcomes." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 17 Correlation, Causation, and LM | PPLS PhD Training Workshop: Statistics and R" />
  
  <meta name="twitter:description" content="This is the main page of the course and contains a course overview, schedule and learning outcomes." />
  

<meta name="author" content="Anastasia Ushakova and Emma Waterston">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="examining-relationships-more-than-one-variable.html">
<link rel="next" href="model-selection.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PPLS Summer Training (R and Stats)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview of the Course</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#programme"><i class="fa fa-check"></i>Programme</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preparation"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#data-sets"><i class="fa fa-check"></i>Data sets</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#expectations"><i class="fa fa-check"></i>Expectations</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#lets-stay-in-touch"><i class="fa fa-check"></i>Lets stay in touch</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#list-of-extra-resources"><i class="fa fa-check"></i>List of extra resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#authorship"><i class="fa fa-check"></i>Authorship</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#last-but-not-least"><i class="fa fa-check"></i>Last, but not least</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started-in-rstudio.html"><a href="getting-started-in-rstudio.html"><i class="fa fa-check"></i><b>1</b> Getting Started in RStudio</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started-in-rstudio.html"><a href="getting-started-in-rstudio.html#r-as-an-interactive-envrionment"><i class="fa fa-check"></i><b>1.1</b> R as an interactive envrionment</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started-in-rstudio.html"><a href="getting-started-in-rstudio.html#setting-up-your-working-directory"><i class="fa fa-check"></i><b>1.2</b> Setting Up Your Working Directory</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-console.html"><a href="the-console.html"><i class="fa fa-check"></i><b>2</b> The Console</a><ul>
<li class="chapter" data-level="2.1" data-path="the-console.html"><a href="the-console.html#spacing"><i class="fa fa-check"></i><b>2.1</b> Spacing</a></li>
<li class="chapter" data-level="2.2" data-path="the-console.html"><a href="the-console.html#typos"><i class="fa fa-check"></i><b>2.2</b> Typos</a></li>
<li class="chapter" data-level="2.3" data-path="the-console.html"><a href="the-console.html#unfinishe.-d"><i class="fa fa-check"></i><b>2.3</b> Unfinishe…. d</a></li>
<li class="chapter" data-level="2.4" data-path="the-console.html"><a href="the-console.html#basic-arithmetic"><i class="fa fa-check"></i><b>2.4</b> Basic Arithmetic</a></li>
<li class="chapter" data-level="2.5" data-path="the-console.html"><a href="the-console.html#using-functions-for-calculations"><i class="fa fa-check"></i><b>2.5</b> Using Functions for Calculations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="r-scripts.html"><a href="r-scripts.html"><i class="fa fa-check"></i><b>3</b> R Scripts</a><ul>
<li class="chapter" data-level="3.1" data-path="r-scripts.html"><a href="r-scripts.html#short-example"><i class="fa fa-check"></i><b>3.1</b> Short Example</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="naming-variables.html"><a href="naming-variables.html"><i class="fa fa-check"></i><b>4</b> Naming variables</a></li>
<li class="chapter" data-level="5" data-path="vectors.html"><a href="vectors.html"><i class="fa fa-check"></i><b>5</b> Vectors</a><ul>
<li class="chapter" data-level="5.1" data-path="vectors.html"><a href="vectors.html#numeric-data"><i class="fa fa-check"></i><b>5.1</b> Numeric Data</a></li>
<li class="chapter" data-level="5.2" data-path="vectors.html"><a href="vectors.html#textcharacter-data"><i class="fa fa-check"></i><b>5.2</b> Text/Character Data</a></li>
<li class="chapter" data-level="5.3" data-path="vectors.html"><a href="vectors.html#logical-data"><i class="fa fa-check"></i><b>5.3</b> Logical Data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="vectors.html"><a href="vectors.html#exercise"><i class="fa fa-check"></i><b>5.3.1</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="variable-classes.html"><a href="variable-classes.html"><i class="fa fa-check"></i><b>6</b> Variable Classes</a><ul>
<li class="chapter" data-level="6.1" data-path="variable-classes.html"><a href="variable-classes.html#factors"><i class="fa fa-check"></i><b>6.1</b> Factors</a><ul>
<li class="chapter" data-level="6.1.1" data-path="variable-classes.html"><a href="variable-classes.html#exercise-1"><i class="fa fa-check"></i><b>6.1.1</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lists.html"><a href="lists.html"><i class="fa fa-check"></i><b>7</b> Lists</a></li>
<li class="chapter" data-level="8" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>8</b> Matrices</a></li>
<li class="chapter" data-level="9" data-path="data-frames.html"><a href="data-frames.html"><i class="fa fa-check"></i><b>9</b> Data Frames</a></li>
<li class="chapter" data-level="10" data-path="loading-data.html"><a href="loading-data.html"><i class="fa fa-check"></i><b>10</b> Loading Data</a><ul>
<li class="chapter" data-level="10.1" data-path="loading-data.html"><a href="loading-data.html#practical-example"><i class="fa fa-check"></i><b>10.1</b> Practical Example</a></li>
<li class="chapter" data-level="10.2" data-path="loading-data.html"><a href="loading-data.html#subsetting-dataframes"><i class="fa fa-check"></i><b>10.2</b> Subsetting Dataframes</a><ul>
<li class="chapter" data-level="10.2.1" data-path="loading-data.html"><a href="loading-data.html#replacing-values-nas"><i class="fa fa-check"></i><b>10.2.1</b> Replacing Values &amp; NAs</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="loading-data.html"><a href="loading-data.html#indexing-data-frames"><i class="fa fa-check"></i><b>10.3</b> Indexing Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i><b>11</b> Packages</a></li>
<li class="chapter" data-level="12" data-path="summary-statistics.html"><a href="summary-statistics.html"><i class="fa fa-check"></i><b>12</b> Summary Statistics</a><ul>
<li class="chapter" data-level="12.1" data-path="summary-statistics.html"><a href="summary-statistics.html#data-cleaning"><i class="fa fa-check"></i><b>12.1</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="visualisations.html"><a href="visualisations.html"><i class="fa fa-check"></i><b>13</b> Visualisations</a><ul>
<li class="chapter" data-level="13.1" data-path="visualisations.html"><a href="visualisations.html#simple-plots"><i class="fa fa-check"></i><b>13.1</b> Simple Plots</a><ul>
<li class="chapter" data-level="13.1.1" data-path="visualisations.html"><a href="visualisations.html#using-plot"><i class="fa fa-check"></i><b>13.1.1</b> Using <code>plot()</code></a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="visualisations.html"><a href="visualisations.html#customising-plots"><i class="fa fa-check"></i><b>13.2</b> Customising Plots</a><ul>
<li class="chapter" data-level="13.2.1" data-path="visualisations.html"><a href="visualisations.html#labels"><i class="fa fa-check"></i><b>13.2.1</b> Labels</a></li>
<li class="chapter" data-level="13.2.2" data-path="visualisations.html"><a href="visualisations.html#plot-type"><i class="fa fa-check"></i><b>13.2.2</b> Plot Type</a></li>
<li class="chapter" data-level="13.2.3" data-path="visualisations.html"><a href="visualisations.html#other-customisable-features"><i class="fa fa-check"></i><b>13.2.3</b> Other Customisable Features</a></li>
<li class="chapter" data-level="13.2.4" data-path="visualisations.html"><a href="visualisations.html#change-axes"><i class="fa fa-check"></i><b>13.2.4</b> Change Axes</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="visualisations.html"><a href="visualisations.html#dont-panic"><i class="fa fa-check"></i><b>13.3</b> Don’t Panic!</a></li>
<li class="chapter" data-level="13.4" data-path="visualisations.html"><a href="visualisations.html#other-simple-plots"><i class="fa fa-check"></i><b>13.4</b> Other Simple Plots</a><ul>
<li class="chapter" data-level="13.4.1" data-path="visualisations.html"><a href="visualisations.html#histograms"><i class="fa fa-check"></i><b>13.4.1</b> Histograms</a></li>
<li class="chapter" data-level="13.4.2" data-path="visualisations.html"><a href="visualisations.html#boxplots"><i class="fa fa-check"></i><b>13.4.2</b> Boxplots</a></li>
<li class="chapter" data-level="13.4.3" data-path="visualisations.html"><a href="visualisations.html#scatterplots"><i class="fa fa-check"></i><b>13.4.3</b> Scatterplots</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="visualisations.html"><a href="visualisations.html#how-to-save-image-files"><i class="fa fa-check"></i><b>13.5</b> How to Save Image Files</a></li>
<li class="chapter" data-level="13.6" data-path="visualisations.html"><a href="visualisations.html#plotting-with-ggplot2"><i class="fa fa-check"></i><b>13.6</b> Plotting with <code>ggplot2</code></a><ul>
<li class="chapter" data-level="13.6.1" data-path="visualisations.html"><a href="visualisations.html#ggplot"><i class="fa fa-check"></i><b>13.6.1</b> <code>ggplot()</code></a></li>
<li class="chapter" data-level="13.6.2" data-path="visualisations.html"><a href="visualisations.html#iris-example"><i class="fa fa-check"></i><b>13.6.2</b> Iris Example</a></li>
<li class="chapter" data-level="13.6.3" data-path="visualisations.html"><a href="visualisations.html#ggplot-with-our-mydata-file"><i class="fa fa-check"></i><b>13.6.3</b> <code>ggplot()</code> with our <code>mydata</code> file</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="visualisations.html"><a href="visualisations.html#bring-it-all-together"><i class="fa fa-check"></i><b>13.7</b> Bring It All Together</a></li>
<li class="chapter" data-level="13.8" data-path="visualisations.html"><a href="visualisations.html#write-out-files"><i class="fa fa-check"></i><b>13.8</b> Write Out Files</a></li>
<li class="chapter" data-level="13.9" data-path="visualisations.html"><a href="visualisations.html#questions"><i class="fa fa-check"></i><b>13.9</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="diy.html"><a href="diy.html"><i class="fa fa-check"></i><b>14</b> DIY</a></li>
<li class="chapter" data-level="15" data-path="tests-and-modelling-in-r.html"><a href="tests-and-modelling-in-r.html"><i class="fa fa-check"></i><b>15</b> Tests and modelling in R</a><ul>
<li class="chapter" data-level="15.1" data-path="tests-and-modelling-in-r.html"><a href="tests-and-modelling-in-r.html#hypothesis-testing"><i class="fa fa-check"></i><b>15.1</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="examining-relationships-more-than-one-variable.html"><a href="examining-relationships-more-than-one-variable.html"><i class="fa fa-check"></i><b>16</b> Examining Relationships (more than one variable)</a><ul>
<li class="chapter" data-level="16.1" data-path="examining-relationships-more-than-one-variable.html"><a href="examining-relationships-more-than-one-variable.html#t-test"><i class="fa fa-check"></i><b>16.1</b> T test</a></li>
<li class="chapter" data-level="16.2" data-path="examining-relationships-more-than-one-variable.html"><a href="examining-relationships-more-than-one-variable.html#chi-squared-distribution-and-test"><i class="fa fa-check"></i><b>16.2</b> Chi squared distribution and test</a><ul>
<li class="chapter" data-level="16.2.1" data-path="examining-relationships-more-than-one-variable.html"><a href="examining-relationships-more-than-one-variable.html#contingency-tables"><i class="fa fa-check"></i><b>16.2.1</b> Contingency tables</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="examining-relationships-more-than-one-variable.html"><a href="examining-relationships-more-than-one-variable.html#chi-squared-distribution"><i class="fa fa-check"></i><b>16.3</b> Chi squared distribution</a></li>
<li class="chapter" data-level="16.4" data-path="examining-relationships-more-than-one-variable.html"><a href="examining-relationships-more-than-one-variable.html#one-way-anova"><i class="fa fa-check"></i><b>16.4</b> One way Anova</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html"><i class="fa fa-check"></i><b>17</b> Correlation, Causation, and LM</a><ul>
<li class="chapter" data-level="17.1" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html#sharks-and-ice-cream-example"><i class="fa fa-check"></i><b>17.1</b> Sharks and ice cream example</a></li>
<li class="chapter" data-level="17.2" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html#simple-linear-regression-in-r"><i class="fa fa-check"></i><b>17.2</b> Simple Linear Regression in R</a></li>
<li class="chapter" data-level="17.3" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html#regression-diagnostics---assess-the-validity-of-a-model"><i class="fa fa-check"></i><b>17.3</b> Regression Diagnostics - assess the validity of a model</a><ul>
<li class="chapter" data-level="17.3.1" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html#violations-of-the-assumptions-available-treatments"><i class="fa fa-check"></i><b>17.3.1</b> Violations of the assumptions: available treatments</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html#standardisation"><i class="fa fa-check"></i><b>17.4</b> Standardisation</a></li>
<li class="chapter" data-level="17.5" data-path="correlation-causation-and-lm.html"><a href="correlation-causation-and-lm.html#interaction-simple-slope-and-multiple-explanatory-factors"><i class="fa fa-check"></i><b>17.5</b> Interaction (simple slope) and multiple explanatory factors</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>18</b> Model selection</a><ul>
<li class="chapter" data-level="18.1" data-path="model-selection.html"><a href="model-selection.html#aic-bic"><i class="fa fa-check"></i><b>18.1</b> AIC &amp; BIC</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="diy-1.html"><a href="diy-1.html"><i class="fa fa-check"></i><b>19</b> DIY</a></li>
<li class="chapter" data-level="20" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html"><i class="fa fa-check"></i><b>20</b> Simple Linear Model and Mixed Methods</a><ul>
<li class="chapter" data-level="20.1" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#data-sets-1"><i class="fa fa-check"></i><b>20.1</b> Data sets</a></li>
<li class="chapter" data-level="20.2" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#longitudinal-data"><i class="fa fa-check"></i><b>20.2</b> Longitudinal Data</a></li>
<li class="chapter" data-level="20.3" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#why-a-new-model"><i class="fa fa-check"></i><b>20.3</b> Why a new model?</a></li>
<li class="chapter" data-level="20.4" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#ecological-fallacy-quick-illustration---no-need-to-run"><i class="fa fa-check"></i><b>20.4</b> Ecological Fallacy (quick illustration) - no need to run</a></li>
<li class="chapter" data-level="20.5" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#simple-example"><i class="fa fa-check"></i><b>20.5</b> Simple Example</a></li>
<li class="chapter" data-level="20.6" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#now-for-advanced-model-set-up"><i class="fa fa-check"></i><b>20.6</b> Now for Advanced: Model set up</a><ul>
<li class="chapter" data-level="20.6.1" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#pooling"><i class="fa fa-check"></i><b>20.6.1</b> Pooling</a></li>
<li class="chapter" data-level="20.6.2" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#no-pooling"><i class="fa fa-check"></i><b>20.6.2</b> No pooling</a></li>
<li class="chapter" data-level="20.6.3" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#partial-pooling-varying-intercepts"><i class="fa fa-check"></i><b>20.6.3</b> Partial Pooling (varying intercepts)</a></li>
<li class="chapter" data-level="20.6.4" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#partial-pooling-extended---varying-intercepts-andor-slopes"><i class="fa fa-check"></i><b>20.6.4</b> Partial Pooling Extended - (varying intercepts and/or slopes)</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#multilevel-modelling-with-random-intercepts-and-slopes"><i class="fa fa-check"></i><b>20.7</b> Multilevel modelling with random intercepts and slopes</a><ul>
<li class="chapter" data-level="20.7.1" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#overview-of-the-data-set"><i class="fa fa-check"></i><b>20.7.1</b> Overview of the data set</a></li>
<li class="chapter" data-level="20.7.2" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#prepare"><i class="fa fa-check"></i><b>20.7.2</b> Prepare</a></li>
</ul></li>
<li class="chapter" data-level="20.8" data-path="simple-linear-model-and-mixed-methods.html"><a href="simple-linear-model-and-mixed-methods.html#random-slopes-intercepts-and-cross-level-interactions-optional"><i class="fa fa-check"></i><b>20.8</b> Random slopes, intercepts and cross level interactions (optional)</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="testing-the-assumptions.html"><a href="testing-the-assumptions.html"><i class="fa fa-check"></i><b>21</b> Testing the assumptions</a></li>
<li class="chapter" data-level="22" data-path="coffee-break.html"><a href="coffee-break.html"><i class="fa fa-check"></i><b>22</b> Coffee break</a></li>
<li class="chapter" data-level="23" data-path="logistic-setting.html"><a href="logistic-setting.html"><i class="fa fa-check"></i><b>23</b> Logistic setting</a><ul>
<li class="chapter" data-level="23.1" data-path="logistic-setting.html"><a href="logistic-setting.html#simple-example-1"><i class="fa fa-check"></i><b>23.1</b> Simple Example</a><ul>
<li class="chapter" data-level="23.1.1" data-path="logistic-setting.html"><a href="logistic-setting.html#optional-odds-refresher"><i class="fa fa-check"></i><b>23.1.1</b> Optional (Odds Refresher)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="now-for-advanced-logistic-mixed-effects.html"><a href="now-for-advanced-logistic-mixed-effects.html"><i class="fa fa-check"></i><b>24</b> Now for Advanced: logistic mixed effects</a></li>
<li class="chapter" data-level="25" data-path="now-over-to-you.html"><a href="now-over-to-you.html"><i class="fa fa-check"></i><b>25</b> Now, over to you!</a><ul>
<li class="chapter" data-level="25.1" data-path="now-over-to-you.html"><a href="now-over-to-you.html#data-description"><i class="fa fa-check"></i><b>25.1</b> Data Description</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html"><i class="fa fa-check"></i><b>26</b> Introduction to Bayesian Estimation</a><ul>
<li class="chapter" data-level="26.1" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#intro-to-bayesian-estimation"><i class="fa fa-check"></i><b>26.1</b> Intro to Bayesian estimation</a><ul>
<li class="chapter" data-level="26.1.1" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#data-sets-2"><i class="fa fa-check"></i><b>26.1.1</b> Data sets</a></li>
</ul></li>
<li class="chapter" data-level="26.2" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#bayes-inference-and-one-sample-t-test"><i class="fa fa-check"></i><b>26.2</b> Bayes inference and one-sample t-test</a></li>
<li class="chapter" data-level="26.3" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#difference-between-two-groups-means"><i class="fa fa-check"></i><b>26.3</b> Difference between two groups’ means</a></li>
<li class="chapter" data-level="26.4" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#bayes-factor-example"><i class="fa fa-check"></i><b>26.4</b> Bayes Factor Example</a></li>
<li class="chapter" data-level="26.5" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#bayes-factor-and-anova"><i class="fa fa-check"></i><b>26.5</b> Bayes Factor and Anova</a><ul>
<li class="chapter" data-level="26.5.1" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#exercise-2"><i class="fa fa-check"></i><b>26.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="26.6" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#linear-models-with-bas"><i class="fa fa-check"></i><b>26.6</b> Linear models with BAS</a><ul>
<li class="chapter" data-level="26.6.1" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#bic-and-r-squared"><i class="fa fa-check"></i><b>26.6.1</b> BIC and R squared</a></li>
</ul></li>
<li class="chapter" data-level="26.7" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#predictions-from-bas.lm"><i class="fa fa-check"></i><b>26.7</b> Predictions from bas.lm</a></li>
<li class="chapter" data-level="26.8" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#examining-and-presenting-results"><i class="fa fa-check"></i><b>26.8</b> Examining and presenting results</a></li>
<li class="chapter" data-level="26.9" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#bayesian-mixed-methods-example-optional"><i class="fa fa-check"></i><b>26.9</b> Bayesian Mixed methods example (Optional)</a><ul>
<li class="chapter" data-level="26.9.1" data-path="introduction-to-bayesian-estimation.html"><a href="introduction-to-bayesian-estimation.html#data"><i class="fa fa-check"></i><b>26.9.1</b> Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="diy-2.html"><a href="diy-2.html"><i class="fa fa-check"></i><b>27</b> DIY</a><ul>
<li class="chapter" data-level="27.1" data-path="diy-2.html"><a href="diy-2.html#extra-resources-to-check"><i class="fa fa-check"></i><b>27.1</b> Extra Resources to check</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="extra-resources.html"><a href="extra-resources.html"><i class="fa fa-check"></i><b>28</b> Extra Resources</a><ul>
<li class="chapter" data-level="28.1" data-path="extra-resources.html"><a href="extra-resources.html#more-r-practice"><i class="fa fa-check"></i><b>28.1</b> More R practice</a></li>
<li class="chapter" data-level="28.2" data-path="extra-resources.html"><a href="extra-resources.html#data-cleaning-1"><i class="fa fa-check"></i><b>28.2</b> Data Cleaning</a></li>
<li class="chapter" data-level="28.3" data-path="extra-resources.html"><a href="extra-resources.html#visualisations-1"><i class="fa fa-check"></i><b>28.3</b> Visualisations</a></li>
<li class="chapter" data-level="28.4" data-path="extra-resources.html"><a href="extra-resources.html#other-common-methods-in-r"><i class="fa fa-check"></i><b>28.4</b> Other Common Methods in R</a></li>
<li class="chapter" data-level="28.5" data-path="extra-resources.html"><a href="extra-resources.html#big-data"><i class="fa fa-check"></i><b>28.5</b> Big Data</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PPLS PhD Training Workshop: Statistics and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="correlation-causation-and-lm" class="section level1">
<h1><span class="header-section-number">Chapter 17</span> Correlation, Causation, and LM</h1>
<p>Things are often correlated, and such correlations are often random and may be attributed to scales of your variables and just reflect numerical variability rather than true relationship. Always have an idea in mind before setting up and claiming any relationship in your data instead of just looking at the relationships and then suggesting there is one.</p>
<p>To see some fun spurious correlations you can have a look <a href="http://www.tylervigen.com/spurious-correlations">here</a></p>
<p>We will illustrate this with a very silly example. We have got some data on ice cream sales and shark attacks, and have found that there was a <em>significant</em> and <em>positive</em> correlation. Lets get data in and see what has happened there.</p>
<div id="sharks-and-ice-cream-example" class="section level2">
<h2><span class="header-section-number">17.1</span> Sharks and ice cream example</h2>
<pre class="sourceCode r"><code class="sourceCode r">sharks &lt;-<span class="kw">read.csv</span>(<span class="st">&#39;shark_attacks.csv&#39;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(psych)</code></pre>
<p>Lets check the structure and describe the data:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(sharks)</code></pre>
<pre><code>## &#39;data.frame&#39;:    84 obs. of  5 variables:
##  $ Year         : int  2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 ...
##  $ Month        : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ SharkAttacks : int  25 28 32 35 38 41 43 40 38 33 ...
##  $ Temperature  : num  11.9 15.2 17.2 18.5 19.4 22.1 25.1 23.4 22.6 18.1 ...
##  $ IceCreamSales: int  76 79 91 95 103 108 102 98 83 83 ...</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">describe</span>(sharks)</code></pre>
<pre><code>##               vars  n    mean    sd  median trimmed   mad    min     max
## Year             1 84 2011.00  2.01 2011.00 2011.00  2.97 2008.0 2014.00
## Month            2 84    6.50  3.47    6.50    6.50  4.45    1.0   12.00
## SharkAttacks     3 84   34.00  8.44   35.00   34.34 10.38   14.0   50.00
## Temperature      4 84   18.73  4.03   18.38   18.85  5.02   10.7   25.36
## IceCreamSales    5 84   88.17 13.40   91.00   88.47 17.79   64.0  109.00
##               range  skew kurtosis   se
## Year           6.00  0.00    -1.29 0.22
## Month         11.00  0.00    -1.26 0.38
## SharkAttacks  36.00 -0.26    -0.92 0.92
## Temperature   14.66 -0.07    -0.89 0.44
## IceCreamSales 45.00 -0.15    -1.35 1.46</code></pre>
<p>And also visualise:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">qplot</span>(sharks<span class="op">$</span>SharkAttacks, sharks<span class="op">$</span>IceCreamSales, 
      <span class="dt">xlab=</span><span class="st">&#39;Shark Attacks&#39;</span>,
      <span class="dt">ylab=</span><span class="st">&#39;Ice Cream Sales&#39;</span>,
      <span class="dt">geom=</span><span class="st">&quot;point&quot;</span>)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-162-1.png" width="672" /></p>
<p>It seems that there may be a positive relationship between shark attacks and ice cream sales based on the plot. Let’s check (and test!) for significance of the correlation. You can do this using `cor.test’.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(sharks<span class="op">$</span>SharkAttacks, sharks<span class="op">$</span>IceCreamSales)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  sharks$SharkAttacks and sharks$IceCreamSales
## t = 5.7247, df = 82, p-value = 1.648e-07
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.3613613 0.6717900
## sample estimates:
##       cor 
## 0.5343576</code></pre>
<p>Based on the output, there is a significant and positive correlation between shark attacks and ice cream sales as <em>r</em> = .53, <em>p</em> &lt; .001.</p>
<p>What do you think has happened here? There may be of course some confounding variables we forgot to control for. Those could also be <em>mediating</em> the relationship so we cannot observe the true association of ice cream sales on shark attacks. The true relationship that we should expect would be <strong>no</strong> association, and something else must be in an interplay here. Lets run a simple linear model and try to build up our analysis:</p>
</div>
<div id="simple-linear-regression-in-r" class="section level2">
<h2><span class="header-section-number">17.2</span> Simple Linear Regression in R</h2>
<p>Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. Every value of the independent variable x is associated with a value of the dependent variable (y).</p>
<p>We are looking at the following set up. Where _0 represents the expected value of shark attacks when no ice cream has been sold and where _1 would suggest to us the marginal effect of every unit increase in ice cream sale from the number of shark attacks.</p>
<p><span class="math display">\[\begin{equation}
Y_[i] = \beta_0 + \beta_1 * X_i + \epsilon_i

\end{equation}\]</span></p>
<p>More specifically:</p>
<p><span class="math display">\[\begin{equation}
Shark Attacks = \beta_0 + \beta_1 * Ice Cream Sales

\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Run the model</span>
sharks_model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(SharkAttacks <span class="op">~</span><span class="st"> </span>IceCreamSales, <span class="dt">data =</span> sharks)
<span class="co">#Summarise the output</span>
<span class="kw">summary</span>(sharks_model1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = SharkAttacks ~ IceCreamSales, data = sharks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.5813  -4.6829  -0.9704   4.8391  17.7726 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    4.35231    5.23776   0.831    0.408    
## IceCreamSales  0.33627    0.05874   5.725 1.65e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.173 on 82 degrees of freedom
## Multiple R-squared:  0.2855, Adjusted R-squared:  0.2768 
## F-statistic: 32.77 on 1 and 82 DF,  p-value: 1.648e-07</code></pre>
<p>Lets study the output carefully, what is your _0, _1?</p>
<p>What do you conclude about the overall model? What about R squared values? F statistic?</p>
<p>We would say that ice cream sales can ‘predict’ the number of shark attacks, and that ice cream sales account for 27.68% of the variance in shark attacks. The F-statistic is a good indicator of whether there is a relationship between our predictor and the response variables. The further the F-statistic is from 1 the ‘better it is’, and ours is relatively big (and significant) given our number of data points.</p>
<p>Remember that <strong>R squared</strong> represents the ratio of explained variance by the model over total variation in your data. While the <strong>F statistic</strong> is used to test the hypothesis that the model you set up is better than null/no model or that the ratio of explained variance over total will be different once we set up the model with few explanatory variables.</p>
<p>In general, this model isn’t <em>that</em> bad if you were to look at explanatory power. However, we know that it doesn’t make much sense! Let us add the <em>temperature</em> variable into the setting.</p>
<p>More specifically:</p>
<p><span class="math display">\[\begin{equation}
Shark Attacks = \beta_0 + \beta_1 * Ice Cream Sales + \beta_2 * Temperature

\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Adding extra variable</span>
sharks_model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(SharkAttacks <span class="op">~</span><span class="st"> </span>IceCreamSales <span class="op">+</span><span class="st"> </span>Temperature, <span class="dt">data =</span> sharks)

<span class="co">#Summarise</span>
<span class="kw">summary</span>(sharks_model2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = SharkAttacks ~ IceCreamSales + Temperature, data = sharks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.2433  -2.6065  -0.0976   2.8733  16.6965 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.56510    4.30514   0.131   0.8959    
## IceCreamSales  0.10459    0.05957   1.756   0.0829 .  
## Temperature    1.29276    0.19802   6.528  5.4e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.842 on 81 degrees of freedom
## Multiple R-squared:  0.5319, Adjusted R-squared:  0.5203 
## F-statistic: 46.01 on 2 and 81 DF,  p-value: 4.469e-14</code></pre>
<p>Lets make tables a bit easier to study:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Load a nice package &#39;texreg&#39;</span>
<span class="kw">library</span>(texreg)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">screenreg</span>(<span class="kw">list</span>(sharks_model1, sharks_model2))</code></pre>
<pre><code>## 
## ===================================
##                Model 1    Model 2  
## -----------------------------------
## (Intercept)     4.35       0.57    
##                (5.24)     (4.31)   
## IceCreamSales   0.34 ***   0.10    
##                (0.06)     (0.06)   
## Temperature                1.29 ***
##                           (0.20)   
## -----------------------------------
## R^2             0.29       0.53    
## Adj. R^2        0.28       0.52    
## Num. obs.      84         84       
## RMSE            7.17       5.84    
## ===================================
## *** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05</code></pre>
<p>Looking good! You can now easily compare the models, and suggest that temperature was a confounding variable. We’ll discuss model comparisons in more detail a bit later.</p>
</div>
<div id="regression-diagnostics---assess-the-validity-of-a-model" class="section level2">
<h2><span class="header-section-number">17.3</span> Regression Diagnostics - assess the validity of a model</h2>
<p>Lets try to run a model on a different data set. We will study what ‘predicts’ anxiety levels of students taking statistics course. We have some ideas about revision completeness being one of the reasons why students may feel anxious.</p>
<p>Our model can be written as follows:</p>
<p><span class="math display">\[\begin{equation}
Anxiety = \beta_0 + \beta_1 * Revision 
\end{equation}\]</span></p>
<p>Load the ‘anxiety’ data in:</p>
<pre class="sourceCode r"><code class="sourceCode r">anxiety &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;anxiety.csv&#39;</span>)</code></pre>
<p>Our first task is to describe and visualise the variables of interest. We introduce pair panels here, which is quite a handy way to check for correlations.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Describe</span>
<span class="kw">describe</span>(anxiety)</code></pre>
<pre><code>##         vars   n  mean    sd median trimmed   mad  min    max  range  skew
## Code       1 103 52.00 29.88  52.00   52.00 38.55 1.00 103.00 102.00  0.00
## Revised    2 103 19.85 18.16  15.00   16.70 11.86 0.00  98.00  98.00  1.95
## Exam       3 103 56.57 25.94  60.00   57.75 29.65 2.00 100.00  98.00 -0.36
## Anxiety    4 103 74.34 17.18  79.04   77.05 10.75 0.06  97.58  97.53 -1.95
## Gender*    5 103  1.50  0.50   2.00    1.51  0.00 1.00   2.00   1.00 -0.02
##         kurtosis   se
## Code       -1.24 2.94
## Revised     4.34 1.79
## Exam       -0.91 2.56
## Anxiety     4.73 1.69
## Gender*    -2.02 0.05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Visualise</span>
<span class="kw">pairs.panels</span>(anxiety [, <span class="dv">2</span><span class="op">:</span><span class="dv">4</span>])</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-169-1.png" width="672" /></p>
<p>Lets fit a linear model:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Run the model</span>
model_anx &lt;-<span class="kw">lm</span>(Anxiety <span class="op">~</span><span class="st"> </span>Revised, <span class="dt">data =</span> anxiety)

<span class="co">#Summarise</span>
<span class="kw">summary</span>(model_anx)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Anxiety ~ Revised, data = anxiety)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -76.325  -4.269   1.304   6.415  36.488 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 87.66755    1.78184   49.20   &lt;2e-16 ***
## Revised     -0.67108    0.06637  -10.11   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 12.17 on 101 degrees of freedom
## Multiple R-squared:  0.503,  Adjusted R-squared:  0.4981 
## F-statistic: 102.2 on 1 and 101 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Get confidence intervals</span>
<span class="kw">confint</span>(model_anx, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) 84.1328491 91.2022481
## Revised     -0.8027426 -0.5394183</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#We are 95% confident that for a 1 point increase in revision, the average decrease in anxiety is between 0.8 and 0.5 points. </span></code></pre>
<p>Lets also plot the relationship and fitted line:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot</span>
<span class="kw">plot</span>(anxiety<span class="op">$</span>Revised,anxiety<span class="op">$</span>Anxiety, 
     <span class="dt">main=</span><span class="st">&#39;Relationship between revision and anxiety&#39;</span>, 
     <span class="dt">ylab=</span><span class="st">&#39;Anxiety score&#39;</span>, 
     <span class="dt">xlab=</span><span class="st">&#39;% of all topics revised&#39;</span>, 
     <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>, 
     <span class="dt">pch=</span><span class="dv">9</span>)

<span class="co">#Add the line</span>
<span class="kw">abline</span>(model_anx, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">lwd=</span><span class="dv">4</span>)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-171-1.png" width="672" /></p>
<p>What kind of relationship does there seem to be based on this plot?</p>
<p>Lets check for the assumptions. From first glance do you notice anything?</p>
<p>Perhaps we could say that most of the students in the sample have not completed their revision with scores about 20-40 percent of total topics. We have quite a few students with very high levels of anxiety and those were associated with less than 50 percent of topics being revised.</p>
<p>Can we say that the effect of extra revision on anxiety would be the same for those who are on the lower scale of revision versus high? We can clearly see that the effect might decrease gradually as we tend towards revision=100.</p>
<p>Would we trust the results we found? Lets do some diagnostics!</p>
<p><strong>Data Appropriateness</strong></p>
<ol style="list-style-type: lower-alpha">
<li>The predicted variable (also called the outcome, the dependent variable or Y) should be continuous (measured at interval or ratio level)</li>
<li>The predicted variable should be unbounded, or at least cover a wide range of values</li>
<li>The predictor variable (also called the independent variable or X) should be continuous or binary (i.e., categorical with two levels, which is sometimes also called dichotomous).</li>
</ol>
<p><strong>Independence</strong></p>
<p>Each outcome variable should be independent from the others. This would be violated if there were some pattern of time dependency for instance, or if subjects were clustered into larger units (such as members of the same family or children studying in the same classroom).</p>
<p>Independence can only be checked at design level, so let’s assume that each <strong>anxiety</strong> and <strong>revision</strong> score belongs to a different individual, and nobody has been counted twice or at different times.</p>
<p><strong>Normality of Errors</strong></p>
<p>The errors should be normally distributed (while the original data can have any kind of distribution).</p>
<p>We can check normality of the error by accessing the residual plots generated by the model. We can either look at them all at once but pick one:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Specify that you want table output present you 2x2=4 tables</span>
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="co">#Plot results of the model</span>
<span class="kw">plot</span>(model_anx, <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-172-1.png" width="672" /></p>
<p>Let’s interpret the plots:</p>
<ul>
<li>Top left: residual vs fitted - The plot shows if residuals have non-linear patterns. This pattern is indicated by the red line, which should be approximately flat if the disturbances are homoscedastic. You want to find equally spread residuals around this line with no distinct patterns.</li>
<li>Bottom left: This is the inverse of the plot on the top left, but with the y-axis standardised. The plot shows if the residuals are equally spread across the range of predictors. You are looking for equally spread points.</li>
<li>Top right: qqnorm() plot evaluates the assumption of normality of residuals. If points lie exactly on the line, it is perfectly normal distribution. However, some deviation is to be expected, particularly near the ends (note the upper right), but the deviations should be small.</li>
<li>Bottom right: plot of standardized residuals against the leverage. Leverage is a measure of how much each data point influences the regression. The plot also contours values of Cook’s distance, which reflects how much the fitted values would change if a point was removed. The red smoothed line should stay close to the mid-line and no point should have a large cook’s distance.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</code></pre>
<p>To get to Q-Q plot for instance you then just use:</p>
<p>The plot compares how many points we have in each quantile (top 5%, top 10%, top 25% …) for our residuals and for an “ideal” normal distribution.</p>
<p>So are the two distributions of quantiles similar? In other words, is the data aligned along the diagonal? Mostly, yes. So the assumption of normality of error holds from visual inspection.</p>
<p><strong>Homogeneity of the error term (homoscedasticity)</strong></p>
<p>The errors of prediction (the distance between each real point and the point position predicted by your linear model) should be constant across the entire data range. This means that the errors should not be, for instance, smaller when the y value is small, and larger when the y value is large.</p>
<p>You can explore this one from the plots above. We will need plot 1:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_anx, <span class="dt">which=</span><span class="dv">1</span>)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-175-1.png" width="672" /></p>
<p>We can also perform the test to check this:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)

<span class="kw">ncvTest</span>(model_anx)</code></pre>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 0.8274758, Df = 1, p = 0.363</code></pre>
<p>In this case our <em>p value</em> is greater than 0.05, we thus can conclude that the assumption of constant variance is not violated.</p>
<p>In short, visually, what we want to see - if I align my fitted values (predicted anxiety) along the x axis, how does the corresponding residual (error) look on the y axis? Residuals should be a mixture of everything, large and medium and small. Here, the homoscedasticity of error seems to not fit this criteria at visual inspection; the points are spread around but tend to have greater spread on the right indicating non-constant variation at different value of predicted anxiety. There is more variability at lower levels of predicted anxiety.</p>
<p><em>Quick note</em>: there is another way you can get all diagnostics plots at once using package <code>sjPlot</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sjPlot)
<span class="co">#Use plot_model with type=&#39;diag&#39;</span>
<span class="kw">plot_model</span>(model_anx, <span class="dt">type=</span><span class="st">&#39;diag&#39;</span>)</code></pre>
<pre><code>## [[1]]</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-177-1.png" width="672" /></p>
<pre><code>## 
## [[2]]</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-177-2.png" width="672" /></p>
<pre><code>## 
## [[3]]</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-177-3.png" width="672" /></p>
<p><strong>Measurement</strong></p>
<p>You can check these using <code>describe()</code> and using histograms via <code>hist()</code></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">describe</span>(anxiety)</code></pre>
<pre><code>##         vars   n  mean    sd median trimmed   mad  min    max  range  skew
## Code       1 103 52.00 29.88  52.00   52.00 38.55 1.00 103.00 102.00  0.00
## Revised    2 103 19.85 18.16  15.00   16.70 11.86 0.00  98.00  98.00  1.95
## Exam       3 103 56.57 25.94  60.00   57.75 29.65 2.00 100.00  98.00 -0.36
## Anxiety    4 103 74.34 17.18  79.04   77.05 10.75 0.06  97.58  97.53 -1.95
## Gender*    5 103  1.50  0.50   2.00    1.51  0.00 1.00   2.00   1.00 -0.02
##         kurtosis   se
## Code       -1.24 2.94
## Revised     4.34 1.79
## Exam       -0.91 2.56
## Anxiety     4.73 1.69
## Gender*    -2.02 0.05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(anxiety<span class="op">$</span>Revised)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-178-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(anxiety<span class="op">$</span>Anxiety)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-178-2.png" width="672" /></p>
<p>A very useful key to study Residuals vs Leverage plot is presented below:</p>
<p><img src="diagn.png" width="75%" style="display: block; margin: auto;" /></p>
<p><strong>Linearity</strong></p>
<p>The relation between X and Y should be linear, that is, the data points should align on an approximately straight line. (Note: If the shape is different from a straight line, you might try to transform one or both variables, for example, using a log transformation).</p>
<p>These can be examined visually:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Check for linearity of relation between DV and IV using scatterplot of IV vs DV</span>
<span class="kw">plot</span>(anxiety<span class="op">$</span>Anxiety,anxiety<span class="op">$</span>Revised, 
     <span class="dt">main=</span><span class="st">&#39;Relationship between revision and anxiety&#39;</span>, 
     <span class="dt">ylab=</span><span class="st">&#39;Anxiety score&#39;</span>, 
     <span class="dt">xlab=</span><span class="st">&#39;% of all topics revised&#39;</span>, 
     <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>, 
     <span class="dt">pch=</span><span class="dv">9</span>)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-180-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pearson residuals plot</span>
<span class="kw">residualPlots</span>(model_anx)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-180-2.png" width="672" /></p>
<pre><code>##            Test stat Pr(&gt;|Test stat|)  
## Revised      -1.7293          0.08684 .
## Tukey test   -1.7293          0.08375 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the model, represented by the line, isn&#39;t looking too great. The predictions would be a little off, meaning that the model doesn&#39;t represent the relationship between anxiety and revision that well.</span></code></pre>
<div id="violations-of-the-assumptions-available-treatments" class="section level3">
<h3><span class="header-section-number">17.3.1</span> Violations of the assumptions: available treatments</h3>
<p>One of the most common assumptions that is hard not to violate is homescedasticity. Heteroskedasticity doesn’t distort coefficient estimates, but it does throw off the estimates of the standard errors of the coefficients and the standard error of the regression, as well as the standard errors of predictions. We can use simple standard error corrections in <code>R</code>.</p>
<p>The package <code>lmtest</code> used for robust standard error estimation is presented below. Make sure that <code>texreg</code> is also loaded and package <code>sandwich</code>. We will use this to calculate a new var-cov matrix that will account for heteroscedasticity:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lmtest)
<span class="kw">library</span>(texreg)
<span class="kw">library</span>(sandwich)</code></pre>
<p>We can use function <code>coeftest()</code> to see whether the confidence intervals may be different once we consider heteroscedasticity.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coeftest</span>(model_anx, vcov) <span class="co">#retuns our current model output - essentially a ceofficient matrix</span></code></pre>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 87.667549   1.781844  49.200 &lt; 2.2e-16 ***
## Revised     -0.671080   0.066371 -10.111 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Lets present our new results:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">screenreg</span>(                          <span class="co">#creates text representations of tables and prints them to the R console. </span>
  <span class="kw">coeftest</span>(model_anx,               <span class="co"># coefficient matrix</span>
           <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(model_anx))) <span class="co">#accounts for heteroskedasticity - gives robust SE estimate</span></code></pre>
<pre><code>## 
## ======================
##              Model 1  
## ----------------------
## (Intercept)  87.67 ***
##              (2.25)   
## Revised      -0.67 ***
##              (0.10)   
## ======================
## *** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05</code></pre>
<p>Note that the coefficients will remain the same, it is the standard error that may change once we have added the correction. You can notice now that st.error for the intercept estimate and Revised have increased. We can further put our results together with our main model and overwrite the old standard error in the full output.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Save your corrected errors</span>
corrected_errors &lt;-<span class="st"> </span><span class="kw">coeftest</span>(model_anx, <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(model_anx)) 

<span class="kw">screenreg</span>(model_anx, 
          <span class="dt">override.se =</span> corrected_errors[, <span class="dv">2</span>], <span class="co">#overwrite standard errors</span>
          <span class="dt">override.pval =</span> corrected_errors[, <span class="dv">4</span>]) <span class="co">#overwrite p-value</span></code></pre>
<pre><code>## 
## =======================
##              Model 1   
## -----------------------
## (Intercept)   87.67 ***
##               (2.25)   
## Revised       -0.67 ***
##               (0.10)   
## -----------------------
## R^2            0.50    
## Adj. R^2       0.50    
## Num. obs.    103       
## RMSE          12.17    
## =======================
## *** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05</code></pre>
</div>
</div>
<div id="standardisation" class="section level2">
<h2><span class="header-section-number">17.4</span> Standardisation</h2>
<p>You will find that standardization of your variables or logarithmic transformation may often solve the issue.</p>
<p>You can rescale the dependent variable, and a common rescaling is to use its logarithm, and saving this as a new variable.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Log transform</span>
anxiety<span class="op">$</span>logAnx &lt;-<span class="st"> </span><span class="kw">log</span>(anxiety<span class="op">$</span>Anxiety)
anxiety<span class="op">$</span>logAnx  <span class="co">#check values</span></code></pre>
<pre><code>##   [1]  4.457806  4.485440  4.251035  4.115976  4.494484  4.102743  4.400137
##   [8]  4.328362  4.239483  4.409982  4.370005  4.390193  4.251035  4.317675
##  [15]  3.547143  4.555602  4.328362  4.370005  4.512331  4.167223  4.390193
##  [22]  4.349400  4.179635 -2.882404  4.273745  4.400137  4.154655  3.312730
##  [29]  4.295951  4.494484  4.494484  4.317675  3.774598  4.409982  4.370005
##  [36]  4.370005  3.614479  4.400137  4.419732  3.928565  4.409982  4.359755
##  [43]  4.284910  4.306872  4.328362  4.262454  4.580693  4.215972  4.317675
##  [50]  4.295951  4.538517  4.075739  3.975035  4.438950  4.494484  4.273745
##  [57]  4.409982  4.239483  4.129036  4.227797  4.538517  4.438950  4.409982
##  [64]  4.400137  4.409982  4.512331  4.521136  4.457806  4.284910  4.154655
##  [71]  4.154655  4.273745  4.047986  4.438950  4.438950  4.349400  4.409982
##  [78]  2.302585  3.928565  4.476314  4.429387  4.438950  3.005980  4.467103
##  [85]  4.429387  4.215972  4.564036  4.129036  4.438950  4.529865  4.438950
##  [92]  4.419732  4.295951  4.476314  4.273745  4.457806  4.438950  4.328362
##  [99]  4.262454  4.359755  4.409982  4.370005  4.512331</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">anxiety<span class="op">$</span>logRev &lt;-<span class="st"> </span><span class="kw">log</span>(anxiety<span class="op">$</span>Revised)
anxiety<span class="op">$</span>logRev  <span class="co">#check values - issue with -Inf</span></code></pre>
<pre><code>##   [1] 1.3862944 2.3978953 3.2958369 3.9702919 1.3862944 3.0910425 2.7725887
##   [8] 3.0445224 3.2188758 2.8903718 2.8903718 2.7725887 2.5649494 2.8903718
##  [15] 4.5849675 0.0000000 2.6390573 3.3672958 1.3862944 3.1354942 2.6390573
##  [22] 2.4849066 3.0910425 4.4308168 3.1354942 3.2580965 3.1780538 4.2766661
##  [29] 3.6109179 2.3025851 1.0986123 3.5835189 3.7612001 2.9444390 2.4849066
##  [36] 2.1972246 4.2766661 2.3025851 2.4849066 3.4011974 2.7080502 2.0794415
##  [43] 3.5263605 3.0910425 3.0445224 3.2958369 1.7917595 2.8903718 2.0794415
##  [50] 2.9444390      -Inf 3.9512437 3.6375862 2.9444390 3.1354942 2.3978953
##  [57] 3.2958369 2.8332133 2.5649494 3.7376696 1.3862944 2.0794415 1.7917595
##  [64] 2.3978953 1.9459101 2.7080502 1.3862944 3.3322045 3.0910425 3.3672958
##  [71] 0.6931472 2.7725887 4.0775374 2.3025851 2.5649494 2.0794415 1.6094379
##  [78] 0.6931472 3.6375862 1.3862944 2.3025851 1.7917595 4.2195077 2.0794415
##  [85] 0.0000000 2.6390573 3.7376696 2.5649494 0.0000000 1.0986123 1.6094379
##  [92] 2.4849066 2.9444390 0.6931472 2.9444390 2.3978953 2.7080502 3.1354942
##  [99] 2.5649494 2.6390573 0.0000000 2.1972246 2.9957323</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">anxiety<span class="op">$</span>logRev[anxiety<span class="op">$</span>logRev <span class="op">==</span><span class="st"> &quot;-Inf&quot;</span>] &lt;-<span class="st"> </span><span class="ot">NA</span>

model_anxlog1 &lt;-<span class="st"> </span><span class="kw">lm</span>(logAnx <span class="op">~</span><span class="st"> </span>logRev, <span class="dt">data =</span> anxiety)
<span class="kw">summary</span>(model_anxlog1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = logAnx ~ logRev, data = anxiety)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.6599  0.0076  0.1259  0.2187  0.6224 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.82692    0.20997  22.989  &lt; 2e-16 ***
## logRev      -0.23685    0.07551  -3.137  0.00224 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7437 on 100 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.08958,    Adjusted R-squared:  0.08047 
## F-statistic: 9.839 on 1 and 100 DF,  p-value: 0.002244</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Or incorporate directly into your model if only log transforming oucome variable:</span>
model_anxlog2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Anxiety) <span class="op">~</span><span class="st"> </span>Revised, <span class="dt">data =</span> anxiety) <span class="co">#Our error decreased and is better than our previous model</span>

<span class="co">#Summarise</span>
<span class="kw">summary</span>(model_anxlog1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = logAnx ~ logRev, data = anxiety)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.6599  0.0076  0.1259  0.2187  0.6224 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.82692    0.20997  22.989  &lt; 2e-16 ***
## logRev      -0.23685    0.07551  -3.137  0.00224 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7437 on 100 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.08958,    Adjusted R-squared:  0.08047 
## F-statistic: 9.839 on 1 and 100 DF,  p-value: 0.002244</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model_anxlog2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = log(Anxiety) ~ Revised, data = anxiety)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.6518 -0.0876  0.0296  0.1446  1.0928 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.660219   0.096408  48.338  &lt; 2e-16 ***
## Revised     -0.022509   0.003591  -6.268 9.08e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6586 on 101 degrees of freedom
## Multiple R-squared:  0.2801, Adjusted R-squared:  0.2729 
## F-statistic: 39.29 on 1 and 101 DF,  p-value: 9.084e-09</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#plot</span>
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(model_anxlog1)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-185-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_anxlog2)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-185-2.png" width="672" /></p>
<p>You could also use the <code>scale</code> function:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Scale</span>
anxiety<span class="op">$</span>ScaleAnx &lt;-<span class="st"> </span><span class="kw">scale</span>(anxiety<span class="op">$</span>Anxiety) <span class="co">#now have a mean of 0 and SD of 1</span>
anxiety<span class="op">$</span>ScaleRev &lt;-<span class="st"> </span><span class="kw">scale</span>(anxiety<span class="op">$</span>Rev)

model_anxscale &lt;-<span class="st"> </span><span class="kw">lm</span>(anxiety<span class="op">$</span>ScaleAnx <span class="op">~</span><span class="st"> </span>anxiety<span class="op">$</span>ScaleRev)

<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(model_anxscale)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-186-1.png" width="672" /></p>
<p>It could be the case that you are missing variables, or that you need to instead include a non-linear model. Sometimes the issue may be coming from model specification. We will present a brief example below.</p>
</div>
<div id="interaction-simple-slope-and-multiple-explanatory-factors" class="section level2">
<h2><span class="header-section-number">17.5</span> Interaction (simple slope) and multiple explanatory factors</h2>
<p>Lets try a different example, we now will try to incorporate both continuous and categorical variables as our independent variables. We will also consider the case where our categorical variable may moderate the effect of a continuous one.</p>
<p>Tomorrow we will extend this further to mixed effect models. But for now, lets load the data set that have some salary indicators and we will look at how department and year in service may affect the variation in salary.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Load the data</span>
salary &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;salary.csv&#39;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Describe</span>
<span class="kw">summary</span>(salary)</code></pre>
<pre><code>##     service          salary           dept     
##  Min.   :2.608   Min.   :22.05   Min.   :0.00  
##  1st Qu.:4.126   1st Qu.:30.08   1st Qu.:0.00  
##  Median :4.882   Median :37.79   Median :0.00  
##  Mean   :4.869   Mean   :39.78   Mean   :0.48  
##  3rd Qu.:5.651   3rd Qu.:49.61   3rd Qu.:1.00  
##  Max.   :6.929   Max.   :71.05   Max.   :1.00</code></pre>
<p>We’ll also center our data around the mean here (because nobody has a service of 0 -meaning they all worked at least a month), and also make sure that ‘department’ is coded as factor. Centering will help you interpret the intercept, as it is meaningful within your data range.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># centre on mean</span>
salary<span class="op">$</span>service_m &lt;-<span class="st"> </span>salary<span class="op">$</span>service <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(salary<span class="op">$</span>service)
<span class="co"># dept as factor</span>
salary<span class="op">$</span>dept &lt;-<span class="st"> </span><span class="kw">factor</span>(salary<span class="op">$</span>dept, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Store Manager&quot;</span>, <span class="st">&quot;Accounts&quot;</span>))</code></pre>
<p>Now, lets plot our data to try and get a better understanding of the relationship (if there is one!) between salary and both service and department.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simple plot</span>
<span class="kw">ggplot</span>(<span class="dt">data=</span>salary, <span class="kw">aes</span>(<span class="dt">x=</span>service, <span class="dt">y=</span>salary)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-191-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># with dimension of &#39;dept&#39;</span>
<span class="kw">ggplot</span>(<span class="dt">data=</span>salary, <span class="kw">aes</span>(<span class="dt">x=</span>service, <span class="dt">y=</span>salary,<span class="dt">colour =</span> dept)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-191-2.png" width="672" /></p>
<p>Lets run a very simple model:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Simple model with not interaction</span>
model_salary1 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span>service_m <span class="op">+</span><span class="st"> </span>dept, <span class="dt">data =</span> salary)
<span class="kw">summary</span>(model_salary1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = salary ~ service_m + dept, data = salary)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.9315 -2.2789 -0.5309  2.5806 12.0499 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    30.339      0.952  31.868  &lt; 2e-16 ***
## service_m       4.368      0.667   6.549 3.95e-08 ***
## deptAccounts   19.665      1.377  14.280  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.845 on 47 degrees of freedom
## Multiple R-squared:  0.8499, Adjusted R-squared:  0.8435 
## F-statistic:   133 on 2 and 47 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The next step would be to test whether the relationship between service on salary was different in the accounts and manager departments. The presence of a significant interaction would indicate that the effect of one predictor variable on the response variable is different at different values of the other predictor variable. Lets test whether there is an interaction between service and department:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Interaction</span>
 model_salary2 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span>service_m<span class="op">*</span>dept, <span class="dt">data =</span> salary)
 <span class="kw">summary</span>(model_salary2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = salary ~ service_m * dept, data = salary)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.3320  -2.7217  -0.2861   2.8132   9.9405 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             30.1911     0.9073  33.276  &lt; 2e-16 ***
## service_m                2.7290     0.9227   2.958  0.00488 ** 
## deptAccounts            19.6694     1.3095  15.021  &lt; 2e-16 ***
## service_m:deptAccounts   3.1071     1.2704   2.446  0.01834 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.607 on 46 degrees of freedom
## Multiple R-squared:  0.8672, Adjusted R-squared:  0.8585 
## F-statistic: 100.1 on 3 and 46 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Lets go through the coefficients:</p>
<ul>
<li><em>(Intercept)</em>: Under the manager condition, with a mean service, salary is 30.19.</li>
<li><em>service_m:</em> For every 1 year increase above the average length of service, salary will increase 2.73.</li>
<li><em>deptAccounts:</em> Under the accounts condition, and for an average length of service, salary increases 12.67 in comparison to the manager condition.</li>
<li><em>service_m:deptAccounts:</em> the effect of average length of service is higher by 3.11 under the accounts condition in comparison to the manager condition. In other words, the slope between average service and salary is 2.72+3.11 = 5.83 in the accounts condition.</li>
</ul>
<p>We can note some slight improvements in explained variance, and that the interaction is significant, identifying the moderation effects. We can also plot this to see how it looks in terms of the slope affect. We can use the <code>interactions</code> package to do this, as it has a nice specified function to produce an interaction plot.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Install and load &#39;interactions&#39;</span>
<span class="kw">library</span>(interactions)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">interact_plot</span>(model_salary2, <span class="dt">pred =</span> service_m, <span class="dt">modx =</span> dept, <span class="dt">plot.points =</span> <span class="ot">TRUE</span>,
               <span class="dt">x.label =</span> <span class="st">&quot;Years Service&quot;</span>, <span class="dt">y.label =</span> <span class="st">&quot;Salary (£)&quot;</span>,
               <span class="dt">legend.main =</span> <span class="st">&quot;Department&quot;</span>)</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-195-1.png" width="672" /></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="examining-relationships-more-than-one-variable.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-selection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-lm-testsRmd.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
