[
["index.html", "Multivariate Statistics and Methodology using R Overview of the Course The team R stuff", " Multivariate Statistics and Methodology using R Department of Psychology, University of Edinburgh 2019-2020 Overview of the Course Multivariate Statistics and Methodology using R extends what you learnt last semester in USMR to provide an advanced level overview of statistical analysis techniques and methodology issues relevant to psychological research, introducing analysis tools that extend to cases where multiple outcome variables are being studied simultaneously, and hierarchical data structures (e.g., children nested in classes nested in schools). On this page you will find the weekly lab exercises, along with links to useful content online, walkthroughs, etc. The labs will begin to require a little more initiative than those from USMR, so be prepared to do some googling! Each week, solutions (where available) will be made available here for the previous weeks’ lab. The team Lecturers: Dr Aja Murray: aja.murray@ed.ac.uk (Course Organiser) Dr Dan Mirman: daniel.mirman@ed.ac.uk Senior Teching Coordinators: pg.ppls.stats@ed.ac.uk Dr Umberto Noe Dr Josiah King R stuff We will be getting to grips with a lot of new tools for data manipulation and visualisation, using some of the packages pictured below. Some of you may be familiar with some of these already, but don’t worry if not! R Cheatsheets You can find a collection of cheatshets that summarise some of the most useful commands you will be using for tasks such as data transformation, visualisation, RMarkdown and many others here/ Some key ones for this course are: RMarkdown Data Visualisation (ggplot2) Data transformation with dplyr Data Import R Community R has great representation in Edinburgh. Check out these pages to find out more: R Ladies Edinburgh EdinburghR And worldwide you have: R Studio Community "],
["tidyverse-markdown.html", "Chapter 1 Tidyverse &amp; Markdown 1.1 Data Visualization with ggplot 1.2 Data management with the Tidyverse 1.3 Reproducible research with RMarkdown", " Chapter 1 Tidyverse &amp; Markdown This week, we’re going to introduce you to some really nice packages and tools which will help you to make your analysis and reporting more efficient, aesthetically pleasing, and (importantly) reproducible. Packages If you haven’t previously installed them, install the following packages tidyverse rmarkdown haven (this one is just for reading in data from other software like SPSS or SAS) Lecture slides The lecture slides can be accessed here. The data (in .RData format) for the lecture can be found at https://edin.ac/2suU8XW Background &amp; Reading R for Data Science: https://r4ds.had.co.nz/index.html Data visualization: Chapters 3 and 28 Data management (tidyverse): Chapters 5 and 12 R Markdown: Chapter 27 Extras: Kieran Healey has a brilliant book on getting started with ggplot: Data Visualisation; a practical introduction Another great one is Fundamentals of Data Visualisation by Claus O. Wilke 1.1 Data Visualization with ggplot For plotting, you may be familiar with the popular ggplot2 package from some of the USMR labs last semester. We’re going to be using this more and more, so the first part of today’s lab will focus on ggplot. Visualization is the first step in analysis 1.1.1 Geoms To learn about some of the different functionalities of ggplot, we’re first going to need some data… ► Question Load the ggplot2 package, read in the data using load() and url(), and extract some summary statistics. The data can be found at https://edin.ac/2Erg9ZW. ► Solution library(ggplot2) load(url(&quot;https://edin.ac/2Erg9ZW&quot;)) summary(speech_ses) ## ResponseId Category Accuracy ## Length:912 Social Class:228 Min. : 3.704 ## Class :character Race :228 1st Qu.: 55.556 ## Mode :character Age :228 Median : 66.667 ## Gender :228 Mean : 69.547 ## 3rd Qu.: 82.407 ## Max. :100.000 Data overview Kraus et al. (2019) Evidence for the reproduction of social class in brief speech, Proc. Natl. Acad. Sci. U.S.A. (Study 1) N=189 speakers from the International Dialects of (North American) English Archive. Narrative speech and reading stories. Extracted 7 individual words that were produced by all speakers: “And”, “From”, “Thought”, “Beautiful”, “Imagine”, “Yellow”, and “The”. Participants (N=229, from AMT) Listened to the 7 one-word clips Estimated the speaker’s race, gender, age, and educational attainment Each participant completed this for a random subset of 27 speakers ► Question Make a summary plot showing mean accuracy for each category of judgment hint: try ?stat_summary ► Solution We need to use stat_summary because we want to summarise the y values on our plot into summary value(s) (in the case the mean). We could also calculate the mean accuracy for each category first, and then plot them using geom_bar directly, but stat_summary can be pretty useful #one way of doing this: ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) + stat_summary(fun.y=mean, geom=&quot;bar&quot;) We should also note that stat_summary(fun.y=mean, geom=&quot;bar&quot;) and geom_bar(stat=&quot;summary&quot;,fun.y=mean) are exactly the same! You could get the same plot using: ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) + geom_bar(stat=&quot;summary&quot;,fun.y=mean) ► Question Explore the different ways of showing variability. Construct a plot using each of the following geoms: The top three plots (jitter, boxplots and violins) all show all of the data, so we don’t need to use stat_summary for these. However, the bottom two (errorbars and pointranges) require us to summarise the data into means and standard errors, so we need to use stat_summary(fun.data=mean_se). ► Solution # * Boxplot ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) + geom_boxplot() # * Jitter ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) + geom_jitter(width=0.2, alpha=0.5) # * Violin plot ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) + geom_violin() # * Errorbar ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) + stat_summary(fun.data=mean_se, geom=&quot;errorbar&quot;) # * Pointrange ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) + stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;) ► Question Combine two of the geoms used above to create a visualization of the mean accuracy, a measure of variability, and all of the data points. ► Solution ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) + geom_jitter(width=0.2, alpha=0.5) + stat_summary(fun.data=mean_se, geom=&quot;errorbar&quot;, colour=&quot;black&quot;, width=0.4, size=1.5) ► Question Refine the plot by, for example, removing unnecessary elements, adding useful annotations (e.g., chance performance = 50%), selecting a good color scheme, etc. tip: This is where google becomes really helpful, for example ► Solution ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) + geom_jitter(width=0.2, alpha=0.5) + stat_summary(fun.data=mean_se, geom=&quot;errorbar&quot;, colour=&quot;black&quot;, width=0.4, size=1.5) + guides(colour = FALSE) + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) + geom_hline(yintercept=50, linetype=&quot;dashed&quot;) 1.1.2 Recreating a plot ► Question Recreate the graph below using ggplot (if you like, try to make it better!). Women in computer science The data (in .csv format) can be downloaded from https://edin.ac/2qYA0wr. You can use read.csv(url(&quot;https://edin.ac/2qYA0wr&quot;)) to read it directly into R. ► Solution women_cs&lt;-read.csv(url(&quot;https://edin.ac/2qYA0wr&quot;)) ggplot(women_cs, aes(x=date, y=pct_women_majors, color=field))+ labs(x=NULL,y=NULL, title=&quot;What happened to women in computer science?&quot;)+ geom_line()+ scale_color_manual(values=c(&#39;#11605E&#39;, &#39;#17807E&#39;, &#39;#8BC0BF&#39;,&#39;#D8472B&#39;))+ scale_y_continuous(label=scales::percent)+ theme_minimal(base_family=&quot;Helvetica&quot;)+ theme(legend.title=element_blank()) # If you want to get fancier, and add the labels at the end of the lines, check out the gghighlight package! 1.2 Data management with the Tidyverse A collection of R packages known as the tidyverse provides so many incredibly useful functions that can speed up your workflow. They are often contrasted to Base R (which is what you have been working with so far) in that they provide an alternative grammar which is aimed at being more predictable and consistent. Some people find the tidyverse a lot more intuitive, but others don’t, and the transition can sometimes be difficult! 1.2.1 Piping! It may look a bit weird (%&gt;%), but the pipe operator in R is incredibly useful. Its fundamental role is to ‘chain’ functions together. Previously we wrapped functions around one another, with lots of brackets, but with %&gt;% we can link the intermediate output of one function and take it as the input of another. The two functions f and g, when used in combination like g(f(x)), can now be written as x %&gt;% f() %&gt;% g(). You don’t even always need the brackets, and coulde write x %&gt;% f %&gt;% g! The default behaviour of %&gt;% is to put the output of the LHS (left hand side) in as the first argument in the RHS. However, you can change this by using %&gt;% in combination with a ., to specify which argument you want it to be inputted as: 100 %&gt;% rnorm(10, ., 1) is equal to rnorm(10, 100, 1) The default behaviour: 100 %&gt;% rnorm(0, 1) is implicitly saying 100 %&gt;% rnorm(., 0, 1), which is equal to rnorm(100, 0, 1). ► Question Translate the following statements between Base R and sequences of pipes. The first is shown for you. 1 Base R: round(mean(rnorm(100,0,1))) Pipes : rnorm(100,0,1) %&gt;% mean() %&gt;% round() 2 Base R: x&lt;-10:100 round(exp(diff(log(x))), 2) Pipes: ► Solution 10:100 %&gt;% log() %&gt;% diff() %&gt;% exp() %&gt;% round(2) 3 Pipes: 6 %&gt;% round(pi, digits=.) Base R: ► Solution round(pi, digits=6) 1.2.2 Grouping, summarising, filtering, mutating and selecting Tidyverse also gives us really useful functions for wrangling data. There are many, but some of the key ones we’ll learn here are: select() extracts columns filter() subsets data based on conditions mutate() adds new variables group_by() group related rows together summarise()/summarize() reduces values down to a single summary For a quick example, if we want to calculate the median accuracy for each category, but only after removing those with an accuracy &lt;50, we could use: speech_ses %&gt;% filter(Accuracy&gt;50) %&gt;% group_by(Category) %&gt;% summarise( mdn_accuracy = median(Accuracy) ) And if we wanted to also calculate the mean accuracy for each category, we could add: speech_ses %&gt;% group_by(Category) %&gt;% summarise( n = n(), mean_acc = mean(Accuracy) ) ► Question Load the tidyverse, and haven package, and read in the data using read_sav() (.sav is the type of file which comes out of another stats software, SPSS). You can download the data from https://edin.ac/34n6AWA to your computer, and then read it in. library(tidyverse) exam &lt;- haven::read_sav(&quot;data/exam.sav&quot;) Using the exam.sav data: ► Question Calculate the mean score for each exam ► Solution exam %&gt;% group_by(exam) %&gt;% summarize(M = mean(scores)) ## # A tibble: 3 x 2 ## exam M ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 42.9 ## 2 2 37.9 ## 3 3 38.9 ► Question Calculate the mean score for each exam for female students only ► Solution exam %&gt;% filter(gender==&quot;f&quot;) %&gt;% group_by(exam) %&gt;% summarize(M = mean(scores)) ## # A tibble: 3 x 2 ## exam M ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 43.1 ## 2 2 36.6 ## 3 3 38.1 ► Question Make a new dataframe containing only the exam scores for males for exam number 1, with a new variable indicating whether they passed or not (pass = a score of 40) ► Solution exam_m1 &lt;- exam %&gt;% filter(exam == 1, gender == &quot;m&quot;) %&gt;% mutate(pass = ifelse(scores&gt;40,&quot;pass&quot;,&quot;fail&quot;)) ► Question Calculate the average score for each exam for male and female students&quot;)` ► Solution exam %&gt;% group_by(exam, gender) %&gt;% summarize(M = mean(scores)) ## # A tibble: 6 x 3 ## # Groups: exam [3] ## exam gender M ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 f 43.1 ## 2 1 m 42.7 ## 3 2 f 36.6 ## 4 2 m 39.1 ## 5 3 f 38.1 ## 6 3 m 39.7 # use spread() to make it easier to compare exam %&gt;% group_by(exam, gender) %&gt;% summarize(M = mean(scores)) %&gt;% spread(gender, M) ## # A tibble: 3 x 3 ## # Groups: exam [3] ## exam f m ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 43.1 42.7 ## 2 2 36.6 39.1 ## 3 3 38.1 39.7 1.2.3 Reshaping The same data can be represented in many different ways. We often discern between long and wide formats, and each of these are useful in different ways. Consider, the below example, showing the same data in long format on the left, and in wide on the right. There are some useful functions which we can use to move between these formats: gather() and spread(). Check out the explanation of them in the reading, section 12.3 A newer version of these are pivot_longer() and pivot_wider(), but gather() and spread() will continue to be available if you want them. Data overview The USArrests data set (comes with R) contains violent crime arrests (per 100,000 residents) in each of the 50 states in the USA in 1973 and the percent of the population of each state that lived in urban areas. You can see it by just typing USArrests in R. ► Question Convert the USArrests data set from a wide to a long format so that instead of separate variables for each crime type (Murder, Assault, Rape), there is one variable that identifies the crime type and one variable that contains the rates for each crime type for each state. ► Solution x &lt;- gather(USArrests, key=&quot;CrimeType&quot;, value=&quot;Rate&quot;, Murder, Assault, Rape) # or x &lt;- pivot_longer(USArrests, cols = c(Murder, Assault, Rape), names_to = &quot;CrimeType&quot;, values_to = &quot;Rate&quot;) ► Question Make a scatterplot showing the relationship between each type of violent crime rate and percent of population living in urban areas. ► Solution ggplot(x, aes(UrbanPop, Rate)) + facet_wrap(~CrimeType, scales=&quot;free&quot;, nrow=1) + geom_point() + stat_smooth(method=&quot;lm&quot;) Less guidance Data overview The ability data set in the psych package contains accuracy of 1525 subjects on 16 multiple choice IQ-test-type questions. The questions are of 4 types: basic reasoning, letter sequence, matrix reasoning, and spatial rotation. There are four questions of each type. You can see the by typing psych::ability (those :: are just a way of accessing something from inside a package without loading it). ► Question Tidy the data and make a graph of average accuracy for each question type. You might have to use as_tibble(ability) or as.data.frame(ability) because it is initially stored as a matrix. Hint: the separate() function may come in handy at some point. ► Solution iq &lt;- as_tibble(psych::ability) %&gt;% pivot_longer(., cols=1:16, names_to = &quot;Item&quot;, values_to = &quot;Correct&quot;) %&gt;% # gather(key=&quot;Item&quot;, value=&quot;Correct&quot;, 1:16) %&gt;% # The gather() alternative... separate(Item, c(&quot;Domain&quot;, &quot;Number&quot;)) ggplot(iq, aes(Domain, Correct)) + stat_summary(fun.y = mean, geom=&quot;bar&quot;) 1.3 Reproducible research with RMarkdown We’re also going to start to use RMarkdown. This is a really useful means of making a report reproducible. Essentially, it is a combination of R code and normal text. It will require learning a few new formatting rules (the “markdown” bit), but it means that in one file you can read in and analyse your data, and compile it to a pdf. Which essentially means that if your data or analysis changes, then the results you report change too without having to edit them! 1.3.1 Convert a script into a R Notebook Open your script from the exercises so far. Compile a HTML report from that script. ► Question Create a new R Notebook file, fill it in with the content of your script from the exercises so far.&quot;)` Hint: R code goes into R chunks, add some text in between chunks. Add formatting to make it look nicer: headers, bold, italics, etc (see the cheat-sheet) Add chunk options to suppress extraneous messages and warnings, and to control the size of figures. ► Question Knit the notebook into a HTML file. "],
["basic-multilevel-regression.html", "Chapter 2 Basic Multilevel Regression 2.1 LME4 2.2 Logistic MLR", " Chapter 2 Basic Multilevel Regression We’re going to start using multilevel modelling. There are a whole lot of different names people use for this sort of methodology (hierarchical linear models, linear mixed-effect models, mixed models, nested data models, random coefficient, random-effects models, random parameter models… and so on). What the idea boils down to is that model parameters vary at more than one level. Packages lme4 Lecture Slides Coming soon Background &amp; Reading Winter, 2013 Brauer &amp; Curtin, 2018, (pdf) Luke, 2017 2.1 LME4 We’re going to use the lme4 package, and specifically the functions lmer() and glmer(). “(g)lmer” here stands for “(generalised) linear mixed effects regression”. You will have seen some use of these functions in the lectures. The broad syntax is: lmer(formula, REML = logical, data = dataframe) The formula bit is similar to what we did with a standard linear model (lm()) in that it has the outcome ~ explanatory variables structure. However, we now have the addition of the random effect terms, specified in parenthesis with the | operator separating parameters on the LHS and a grouping factor on the RHS. Below are a selection of different formulas for specifying different random effect structures. Formula Alternative Meaning \\(\\text{(1 | g)}\\) \\(\\text{1 + (1 | g)}\\) Random intercept with fixed mean \\(\\text{0 + offset(o) + (1 | g)}\\) \\(\\text{-1 + offset(o) + (1 | g)}\\) Random intercept with a priori means \\(\\text{(1 | g1/g2)}\\) \\(\\text{(1 | g1) + (1 | g1:g2)}\\) Intercept varying among \\(g1\\) and \\(g2\\) within \\(g1\\) \\(\\text{(1 | g1) + (1 | g2)}\\) \\(\\text{1 + (1 | g1) + (1 | g2)}\\) Intercept varying among \\(g1\\) and \\(g2\\) \\(\\text{x + (x | g)}\\) \\(\\text{1 + x + (1 + x | g)}\\) Correlated random intercept and slope \\(\\text{x + (x || g)}\\) \\(\\text{1 + x + (x | g) + (0 + x | g)}\\) Uncorrelated random intercept and slope Table 1: Examples of the right-hand-sides of mixed effects model formulas. \\(g\\), \\(g1\\), \\(g2\\) are grouping factors, covariats and a priori known offsets are \\(x\\) and \\(o\\). Errors and warnings? For large datasets and/or complex models (lots of random-effects terms), it is quite common to get a convergence warning. There are lots of different ways to deal with these (to try to rule out hypotheses about what is causing them). For now, if lmer() gives you convergence errors, you could try changing the optimizer. Bobyqa is a good one: add control = lmerControl(optimizer = &quot;bobyqa&quot;) when you run your model. ► Question Load the tidyverse, lme4 and effects packages (install them if you haven’t already). ► Solution library(tidyverse) library(lme4) library(effects) 2.1.1 Exercise 1 County-level suicide rate data from Public Health England (PHE) is available at https://edin.ac/36xdhas and covers the period from 2001 to 2016. It contains information for a number of different indicators over this period for a selection of counties in England. ► Question Using multilevel regression, study the following: Did the regions differ in their baseline (2001) suicide rates? Did the regions differ in ther slopes of change of suidice rate? Make a plot of the fitted values from the model Steps: First, get acquainted with the data. It contains various different indicators but we’re only interested in one (suicide rates), so you might want to filter() the data, using the skills you learnt last week. You may also want to center your data on the year 2001, so that the intercept (e.g., at time 0) in your models is interpretable. Then think about what test you can do to answer the questions above. Lastly, passing your model to the effect() function (from the effects package) can give you all the data you need to construct your plot. Hint: Try comparing models with and without different baseline/slopes of suicide rates for each region. Think also about the grouping of the data points, and how this is represented in your random effect structure. ► Solution Loading load(url(&quot;https://edin.ac/36xdhas&quot;)) #load Public Health England data unique(mh_phe[, 1:2]) #check list of mental health indicators: suicide is 41001 ## IndicatorID IndicatorName ## 1 848 Depression: Recorded prevalence (aged 18+) ## 760 41001 Suicide rate ## 8056 90275 Percentage of physically active adults - historical method ## 8664 90646 Depression: QOF incidence (18+) - new diagnosis # select data and shift Year variable so baseline year (2001) is 0 suicide_dat &lt;- filter(mh_phe, IndicatorID == 41001) %&gt;% mutate(Time = Year - 2001) Modelling # base model: just change over time m &lt;- lmer(Value ~ Time + (Time | County), data = suicide_dat, REML = F, control = lmerControl(optimizer = &quot;bobyqa&quot;)) # add baseline differences between regions m.0 &lt;- lmer(Value ~ Time + Region + (Time | County), data = suicide_dat, REML = F, control = lmerControl(optimizer = &quot;bobyqa&quot;)) # add slope differences between regions m.1 &lt;- lmer(Value ~ Time * Region + (Time | County), data = suicide_dat, REML = F, control = lmerControl(optimizer = &quot;bobyqa&quot;)) # compare models anova(m, m.0, m.1) ## Data: suicide_dat ## Models: ## m: Value ~ Time + (Time | County) ## m.0: Value ~ Time + Region + (Time | County) ## m.1: Value ~ Time * Region + (Time | County) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m 6 39961 40002 -19974 39949 ## m.0 14 39924 40019 -19948 39896 53.136 8 1.015e-08 *** ## m.1 22 39918 40068 -19937 39874 21.277 8 0.006447 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 It looks like regions differ in baseline suicide rate (addition of Region predictor in m.0) and in slope of change (addition of interaction in m.1) Plotting # you can extract the fitted values using the effect() function from the effects package. ef &lt;- as.data.frame(effect(&quot;Time:Region&quot;, m.1)) ggplot(ef, aes(Time, fit, color=Region)) + geom_line() + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) + labs(y=&quot;Fitted values&quot;) 2.1.2 Exercise 2 The weight maintenance data (WeightMaintain3), a made-up data set based on Lowe et al. (2014, Obesity, 22, 94-100), contains information on overweight participants who completed a 12-week weight loss program, and were then randomly assigned to one of three weight maintenance conditions: None (Control) MR (meal replacements): use MR to replace one meal and snack per day ED (energy density intervention): book and educational materials on purchasing and preparing foods lower in ED (reducing fat content and/or increasing water content of foods) Weight was assessed at baseline (start of maintenance), 12 months post, 24 months post, and 36 months post. load(url(&quot;https://edin.ac/2tFIedK&quot;)) summary(WeightMaintain3) ## ID Condition Assessment WeightChange ## 101 : 4 None:240 Min. :0.00 Min. :-8.3781 ## 102 : 4 ED :240 1st Qu.:0.75 1st Qu.:-0.5024 ## 103 : 4 MR :240 Median :1.50 Median : 0.7050 ## 104 : 4 Mean :1.50 Mean : 1.4438 ## 105 : 4 3rd Qu.:2.25 3rd Qu.: 2.8806 ## 106 : 4 Max. :3.00 Max. :14.9449 ## (Other):696 ► Question Overall, did the participants maintain their weight loss or did their weights change? ► Solution m.null &lt;- lmer(WeightChange ~ 1 + (Assessment | ID), data=WeightMaintain3, REML=F) m.base &lt;- lmer(WeightChange ~ Assessment + (Assessment | ID), data=WeightMaintain3, REML=F) anova(m.null, m.base) ## Data: WeightMaintain3 ## Models: ## m.null: WeightChange ~ 1 + (Assessment | ID) ## m.base: WeightChange ~ Assessment + (Assessment | ID) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m.null 5 2638.0 2660.9 -1314.0 2628.0 ## m.base 6 2579.4 2606.8 -1283.7 2567.4 60.66 1 6.782e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Weights changed over course of assessment period: \\(\\chi^2(1)=56.5, p &lt;&lt; 0.0001\\) ► Question Did the groups differ in baseline weight change and rate of weight gain (non-maintenance)? ► Solution m.int &lt;- lmer(WeightChange ~ Assessment + Condition + (Assessment | ID), data=WeightMaintain3, REML=F, control = lmerControl(optimizer = &quot;bobyqa&quot;)) m.full &lt;- lmer(WeightChange ~ Assessment*Condition + (Assessment | ID), data=WeightMaintain3, REML=F, control = lmerControl(optimizer = &quot;bobyqa&quot;)) anova(m.null, m.base, m.int, m.full) ## Data: WeightMaintain3 ## Models: ## m.null: WeightChange ~ 1 + (Assessment | ID) ## m.base: WeightChange ~ Assessment + (Assessment | ID) ## m.int: WeightChange ~ Assessment + Condition + (Assessment | ID) ## m.full: WeightChange ~ Assessment * Condition + (Assessment | ID) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m.null 5 2638.0 2660.9 -1314.0 2628.0 ## m.base 6 2579.4 2606.8 -1283.7 2567.4 60.6605 1 6.782e-15 *** ## m.int 8 2573.9 2610.6 -1279.0 2557.9 9.4418 2 0.008907 ** ## m.full 10 2537.5 2583.3 -1258.8 2517.5 40.3814 2 1.703e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Yes: Baseline: \\(\\chi^2(2)=9.4, p &lt; 0.01\\) Slope: \\(\\chi^2(2)=40.4, p &lt;&lt; 0.0001\\) Note: m.int is difficult to interpret in light of the massive effect on slope coef(summary(m.full)) ## Estimate Std. Error t value ## (Intercept) 0.06038642 0.09807901 0.6156916 ## Assessment 1.84917936 0.18394628 10.0528229 ## ConditionED -0.14303302 0.13870466 -1.0312056 ## ConditionMR -0.14944649 0.13870466 -1.0774439 ## Assessment:ConditionED -1.74949968 0.26013932 -6.7252412 ## Assessment:ConditionMR -0.83624053 0.26013932 -3.2145872 Compared to no intervention, weight (re)gain was 1.75 lbs/year slower for the ED intervention and 0.84 lbs/year slower for the MR intervention. Note that baseline weight difference parameters are not significantly different from 0. ► Question Make a graph of the model fit and the observed data ► Solution There are lots of ways you can do this. Using the effect() function again (and then adding the means and SEs from the original data): ef &lt;- as.data.frame(effect(&quot;Assessment:Condition&quot;, m.full)) ggplot(ef, aes(Assessment, fit, color=Condition)) + geom_line() + stat_summary(data=WeightMaintain3, aes(y=WeightChange), fun.data=mean_se, geom=&quot;pointrange&quot;, size=1) + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) 2) Using the fitted() function to extract and plot fitted values from the model: ggplot(WeightMaintain3, aes(Assessment, WeightChange, color=Condition)) + stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;, size=1) + stat_summary(aes(y=fitted(m.full)), fun=mean, geom=&quot;line&quot;) + theme_bw(base_size=12) + scale_color_manual(values=c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;)) Or, alternatively, using fortify(): ggplot(fortify(m.full), aes(Assessment, WeightChange, color=Condition)) + stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;, size=1) + stat_summary(aes(y=.fitted), fun=mean, geom=&quot;line&quot;) + theme_bw(base_size=12) + scale_color_manual(values=c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;)) ► Question Examine the parameter estimates and interpret them (i.e., what does each parameter represent?) ► Solution round(coef(summary(m.full)), 3) ## Estimate Std. Error t value ## (Intercept) 0.060 0.098 0.616 ## Assessment 1.849 0.184 10.053 ## ConditionED -0.143 0.139 -1.031 ## ConditionMR -0.149 0.139 -1.077 ## Assessment:ConditionED -1.749 0.260 -6.725 ## Assessment:ConditionMR -0.836 0.260 -3.215 (Intercept) ==&gt; baseline weight change in None group Assessment ==&gt; slope of weight change in None group ConditionED ==&gt; baseline weight change in ED group relative to None group ConditionMR ==&gt; baseline weight change in MR group relative to None group Assessment:ConditionED ==&gt; slope of weight change in ED group relative to None group Assessment:ConditionMR ==&gt; slope of weight change in MR groups relative to None group 2.2 Logistic MLR 2.2.1 Exercise 3 load(url(&quot;https://edin.ac/2QwG7SG&quot;)) In the nwl data set (accessed using the code above), participants with aphasia are separated into two groups based on the general location of their brain lesion: anterior vs. posterior. There is data on the numbers of correct and incorrect responses participants gave in each of a series of experimental blocks. There were 7 learning blocks, immediately followed by a test. Finally, participants also completed a follow-up test. Compare the two groups (those with anterior vs. posterior lesions) with respect to their responses. Tip: Remember that you can use cbind() to specify the numbers of successes and failures as the outcome in a binomial regression (and remember to specify the family argument in glmer()). ► Question Is the learning rate (training data) different between these two groups? ► Solution m.base &lt;- glmer(cbind(NumCorrect, NumError) ~ block + (block | ID), data = filter(nwl, block &lt; 8, !is.na(lesion_location)), family=binomial) m.loc0 &lt;- glmer(cbind(NumCorrect, NumError) ~ block + lesion_location + (block | ID), data=filter(nwl, block &lt; 8, !is.na(lesion_location)), family=binomial) m.loc1 &lt;- glmer(cbind(NumCorrect, NumError) ~ block * lesion_location + (block | ID), data=filter(nwl, block &lt; 8, !is.na(lesion_location)), family=binomial) #summary(m.loc1) anova(m.base, m.loc0, m.loc1, test=&quot;Chisq&quot;) ## Data: filter(nwl, block &lt; 8, !is.na(lesion_location)) ## Models: ## m.base: cbind(NumCorrect, NumError) ~ block + (block | ID) ## m.loc0: cbind(NumCorrect, NumError) ~ block + lesion_location + (block | ## m.loc0: ID) ## m.loc1: cbind(NumCorrect, NumError) ~ block * lesion_location + (block | ## m.loc1: ID) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m.base 5 454.12 466.27 -222.06 444.12 ## m.loc0 6 454.66 469.25 -221.33 442.66 1.4572 1 0.2274 ## m.loc1 7 454.47 471.48 -220.23 440.47 2.1974 1 0.1382 No significant difference in learning rate between groups: \\(\\chi^2(2)=2.2, p = 0.138\\) ► Question Does their follow-up test performance differ, and does their retention from immediate to follow-up test differ? ► Solution m.recall.loc &lt;- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID), data=filter(nwl, block &gt; 7, !is.na(lesion_location)), family=&quot;binomial&quot;) summary(m.recall.loc) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID) ## Data: filter(nwl, block &gt; 7, !is.na(lesion_location)) ## ## AIC BIC logLik deviance df.resid ## 142.6 150.9 -64.3 128.6 17 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.31708 -0.45013 0.03288 0.46923 1.09355 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.28200 0.5310 ## PhaseImmediate 0.02539 0.1593 1.00 ## Number of obs: 24, groups: ID, 12 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.13826 0.28978 -0.477 0.6333 ## PhaseImmediate 0.02453 0.24634 0.100 0.9207 ## lesion_locationposterior 0.74483 0.38409 1.939 0.0525 . ## PhaseImmediate:lesion_locationposterior 0.25437 0.33904 0.750 0.4531 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) PhsImm lsn_lc ## PhaseImmedt -0.149 ## lsn_lctnpst -0.755 0.113 ## PhsImmdt:l_ 0.109 -0.729 -0.164 ## convergence code: 0 ## boundary (singular) fit: see ?isSingular ► Question Extra: Create a visualisation showing the differences between groups in the average proportion of correct responses at each point in time (i.e., each block, test, and follow-up) ► Solution ggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, color=lesion_location, shape=lesion_location)) + #geom_line(aes(group=ID),alpha=.2) + stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;) + stat_summary(data=filter(nwl, !is.na(lesion_location), block &lt;= 7), fun=mean, geom=&quot;line&quot;) + geom_hline(yintercept=0.5, linetype=&quot;dashed&quot;) + geom_vline(xintercept=c(7.5, 8.5), linetype=&quot;dashed&quot;) + scale_x_continuous(breaks=1:9, labels=c(1:7, &quot;Test&quot;, &quot;Follow-Up&quot;)) + theme_bw(base_size=10) + labs(x=&quot;Block&quot;, y=&quot;Proportion Correct&quot;, shape=&quot;Lesion\\nLocation&quot;, color=&quot;Lesion\\nLocation&quot;) "]
]
