```{r, echo=FALSE}
HIDDEN_SOLS=TRUE
```

# Growth Curve Analysis

`r msmbstyle::question_begin()`
Load the `tidyverse`, `lme4` and `effects` packages, and some useful functions from Dan for getting p-values and coding polynomials.   
  
The `source()` function basically takes in R code and evaluates it. You can look at Dan's scripts online at the URLs ([here](https://uoe-psychology.github.io/uoe_psystats/multivar/functions/get_pvalues.R) and [here](https://uoe-psychology.github.io/uoe_psystats/multivar/functions/code_poly.R)), but sourcing them will read them into your environment. 
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=FALSE, toggle=FALSE)`
```{r warning=FALSE,message=FALSE}
library(tidyverse)
library(lme4)
library(effects)
source('https://uoe-psychology.github.io/uoe_psystats/multivar/functions/get_pvalues.R')
source("https://uoe-psychology.github.io/uoe_psystats/multivar/functions/code_poly.R")
```
`r msmbstyle::solution_end()`

## Exercise 1
<div class="red">
`Az`: Use natural (not orthogonal) polynomials to analyze decline in performance of 30 individuals with probable Alzheimer's disease on three different kinds of tasks - Memory, complex ADL, and simple ADL. 
</div>

`r msmbstyle::question_begin()`
Read the data in to R from the following url: [https://edin.ac/35Njwpl](https://edin.ac/35Njwpl)
. The data is in .rda format. 
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=FALSE)`
```{r}
load("https://edin.ac/35Njwpl")
summary(Az)
```
`r msmbstyle::solution_end()`

* Plot the observed data
* (Why are natural polynomials more useful for these data?)
* Prep the data for GCA
* Fit the GCA model(s)
* Interpret the results: 
    + Which terms show significant effects of experimental factors? 
    + To what extent do model comparisons and the parameter-specific p-values yield the same results?
* Plot observed and model fit data

`r msmbstyle::question_begin()`
Plot the observed data
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
ggplot(Az, aes(Time, Performance, color=Task, fill=Task)) + 
  stat_summary(fun.data=mean_se, geom="ribbon", color=NA, alpha=0.5) +
  stat_summary(fun.y=mean, geom="line")
```
`r msmbstyle::solution_end()`


`r msmbstyle::question_begin()`
Why are natural polynomials more useful for these data?
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
Because it's useful to know whether there are task differences at the starting baseline point
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Fit the GCA models
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
# prep for analysis
Az <- code_poly(Az, predictor="Time", poly.order=2, orthogonal=F, draw.poly = F)

# fit the full model incrementally
m.base <- lmer(Performance ~ (poly1 + poly2) +
                 (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task),
               data=Az, REML=F)
m.0 <- lmer(Performance ~ (poly1 + poly2) + Task +
              (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task),
            data=Az, REML=F)
m.1 <- lmer(Performance ~ poly1*Task + poly2 +
              (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task),
            data=Az, REML=F)
m.Az.full <- lmer(Performance ~ (poly1 + poly2)*Task + 
                  (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task), 
                data=Az, REML=F)
anova(m.base, m.0, m.1, m.Az.full)
```
Get p-values:
```{r warning=FALSE, message=FALSE}
get_pvalues(m.Az.full)
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Interpret the results: 
`r msmbstyle::question_begin()`
Which terms show significant effects of experimental factors? 
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
+ Intercepts are not different: performance in all tasks starts out the same (thanks, natural polynomials)
+ Linear slopes are different: compared to complex ADL tasks, decline in simple ADL tasks is slower and decline in Memory is faster.
+ Quadratic term is different for Memory: decline in cADL and sADL tasks is approximately linear, decline in Memory has more curvature (reaching floor?)
`r msmbstyle::solution_end()`
`r msmbstyle::question_begin()`
To what extent do model comparisons and the parameter-specific p-values yield the same results?
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
jk insert
`r msmbstyle::solution_end()`
`r msmbstyle::question_end()` 

`r msmbstyle::question_begin()`
Plot model fit
`r msmbstyle::question_end()` 
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r fig.width=6, fig.height=4}
ggplot(Az, aes(Time, Performance, color=Task)) + 
  stat_summary(fun.data=mean_se, geom="pointrange") + 
  stat_summary(fun.y=mean, geom="line", aes(y=fitted(m.Az.full)))
```
`r msmbstyle::solution_end()`


## Exercise 2: Logistic GCA
<div class="red">
Re-analyze `TargetFix` data using logistic GCA
</div>




<!--chapter:end:03_gcd.Rmd-->

---
title: 'Lab 1: tidyverse, R Markdown'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background

R for Data Science: https://r4ds.had.co.nz/index.html

* Data visualization: Chapters 3 and 28
* Data management (tidyverse): Chapters 5 and 12
* R Markdown: Chapter 27

# Data Visualization with `ggplot`

Visualization is the first step in analysis

![Same data, different graphs](../figs/SameData_DifferentGraphs.png)

## Exercise 1
Kraus et al. (2019) *Evidence for the reproduction of social class in brief speech*, Proc. Natl. Acad. Sci. U.S.A. (Study 1)

* N=189 speakers from the International Dialects of (North American) English Archive. Narrative speech and reading stories. 
* Extracted 7 individual words that were produced by all speakers: "And", "From", "Thought", "Beautiful", "Imagine", "Yellow", and "The". 
* Participants (N=229, from AMT)
    + Listened to the 7 one-word clips 
    + Estimated the speakerâ€™s race, gender, age, and educational attainment
    + Each participant completed this for a random subset of 27 speakers

```{r message=FALSE}
library(ggplot2)
load("../data/Kraus_etal2019_Study1.Rdata")
summary(speech_ses)
```

## Exercise 1

A. Make a summary plot showing overall accuracy for each category of judgment

B. Explore different ways of showing variability: 

* Errorbar
* Pointrange
* Boxplot
* Violin plot
* Jitter

C. Combine a visualization of the overall accuracy and the variability

D. Refine the plot by, for example, removing unnecessary elements, adding useful annotations (e.g., chance performance = 50%), selecting a good color scheme, etc.

## Exercise 1 Solution
```{r}
# A. Make a summary plot showing overall accuracy for each category of judgment
ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) +
  stat_summary(fun.y=mean, geom="bar")
 
# B. Explore different ways of showing variability: 
# 
# * Errorbar
ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) +
  stat_summary(fun.data=mean_se, geom="errorbar")
# * Pointrange
ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) +
  stat_summary(fun.data=mean_se, geom="pointrange")
# * Boxplot
ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) +
  geom_boxplot()
# * Violin plot
ggplot(speech_ses, aes(x = Category, y = Accuracy, fill = Category)) +
  geom_violin()
# * Jitter
ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) +
  geom_jitter(width=0.2, alpha=0.5)

# C. Combine a visualization of the overall accuracy and the variability

ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) +
  geom_jitter(width=0.2, alpha=0.5) + 
  stat_summary(fun.data=mean_se, geom="errorbar", 
               colour="black", width=0.4, size=1.5)

# D. Refine the plot by, for example, removing unnecessary elements, adding useful annotations (e.g., chance performance = 50%), selecting a good color scheme, etc.
ggplot(speech_ses, aes(x = Category, y = Accuracy, colour = Category)) +
  geom_jitter(width=0.2, alpha=0.5) + 
  stat_summary(fun.data=mean_se, geom="errorbar", 
               colour="black", width=0.4, size=1.5) +
  guides(colour = FALSE) + theme_bw() +
  scale_color_brewer(palette = "Set1") +
  geom_hline(yintercept=50, linetype="dashed")
```

## Exercise 2

A. Pick a published graph and make a better version of it

B. Graphs are usually better than tables. Find a table of results and convert it to a graph.

# Data management with `tidyverse`

## Exercise 1
Using the `exam.sav` data:

A. Calculate the class average score for each exam

B. Calculate the overall average exam score separately for the male students and the female students

C. Calculate the average score for each exam separately for male and female students

## Exercise 1 Solution
```{r ex1, message=FALSE}
library(tidyverse)
exam <- haven::read_sav("../data/exam.sav")

# A. Calculate the class average score for each exam
exam %>% group_by(exam) %>% 
  summarize(M = mean(scores))

# B. Calculate the overall average exam score separately for 
#     the male students and the female students
exam %>% group_by(gender) %>% 
  summarize(M = mean(scores))

# C. Calculate the average score for each exam separately for 
#    male and female students
exam %>% group_by(exam, gender) %>% 
  summarize(M = mean(scores))

#    use spread() to make it easier to compare
exam %>% group_by(exam, gender) %>% 
  summarize(M = mean(scores)) %>% 
  spread(gender, M)
```

## Exercise 2
The `USArrests` data set contains violent crime arrests (per 100,000 residents) in each of the 50 states in the USA in 1973 and the percent of the population of each state that lived in urban areas.

A. Convert the USArrests data set from a wide to a long format so that instead of separate variables for each crime type (Murder, Assault, Rape), there is one variable that identifies the crime type and one variable that contains the rates for each crime type for each state.

B. Make a scatterplot showing the relationship between each type of violent crime rate and percent of population living in urban areas. 

## Exercise 2 Solution
A. Convert the USArrests data set from a wide to a long format so that instead of separate variables for each crime type (Murder, Assault, Rape), there is one variable that identifies the crime type and one variable that contains the rates for each crime type for each state.
```{r}
x <- gather(USArrests, key="CrimeType", value="Rate", 
            Murder, Assault, Rape)
```

B. Make a scatterplot showing the relationship between each type of violent crime rate and percent of population living in urban areas.
```{r fig.height=3}
ggplot(x, aes(UrbanPop, Rate)) + 
  facet_wrap(~CrimeType, scales="free", nrow=1) + 
  geom_point() + stat_smooth(method="lm")
```

## Exercise 3
The `psych::ability` data set contains accuracy of 1525 subjects on 16 multiple choice IQ-test-type questions. The questions are of 4 types: basic reasoning, letter sequence, matrix reasoning, and spatial rotation. There are four questions of each type. Tidy the data and make a graph of average accuracy for each question type.

## Exercise 3 Solution

```{r fig.height=4, warning=FALSE}
iq <- as_tibble(psych::ability) %>% 
  gather(key="Item", value="Correct", 1:16) %>%
  separate(Item, c("Domain", "Number"))
ggplot(iq, aes(Domain, Correct)) + 
  stat_summary(fun.y = mean, geom="bar")
```

# R Markdown

## Exercise 1: Compile a script into a report

Open your script from the exercises so far. Compile a HTML report from that script.

<!-- ![Compile report](../figs/CompileReport.png) -->

## Exercise 2: Convert a script into a R Notebook
A. Create a new `R Notebook` file, fill it in using the content of your script. Knit the notebook into a HTML or PDF file.

Hints:

* Comments become plain text
* R code goes into R chunks

B. Add formatting to make it look nicer: headers, bold, italics, etc.

C. Add chunk options to suppress extraneous messages and warnings, and to control the size of figures.

<!--chapter:end:Lab1_tidyverse-markdown.Rmd-->

---
title: "Lab 02"
author: "Dan Mirman"
output: html_document
---

# Basic MLR

## Exercise 1

Analyze the county-level suicide rate data from PHE (`PHE_MentalHealth.Rdata`) for 2001-2016

*  did the regions differ in their baseline (2001) suicide rates?
*  did the regions differ in ther slopes of change of suidice rate?
*  plot observed data and model fits

## Exercise 1 Solution

```{r}
library(tidyverse)
library(lme4)
library(effects)

load("../data/PHE_MentalHealth.Rdata") #load Public Health England data
unique(mh_phe[, 1:2]) #check list of mental health indicators: suicide is 41001

filter(mh_phe, IndicatorID == 41001) %>%
  ggplot(aes(Year, Value, color = Region)) +
  geom_smooth(method = "lm", se=FALSE)

# select data and shift Year variable so baseline year (2001) is 0
suicide_dat <- filter(mh_phe, IndicatorID == 41001) %>%
  mutate(Time = Year - 2001)
# base model: just change over time
m <- lmer(Value ~ Time + (Time | County), 
          data = suicide_dat, REML = F)
# add baseline differences between regions
m.0 <- lmer(Value ~ Time + Region + (Time | County), 
            data = suicide_dat, REML = F)
# add slope differences between regions
m.1 <- lmer(Value ~ Time * Region + (Time | County), 
            data = suicide_dat, REML = F)
# compare models
anova(m, m.0, m.1)
# regions differ in baseline suicide rate and in slope of change

# visualize effects
ef <- as.data.frame(effect("Time:Region", m.1))
ggplot(ef, aes(Time, fit, color=Region)) + 
  geom_line() +
  theme_bw() + scale_color_brewer(palette = "Set1")
```

## Exercise 2

Analyze the weight maintenance data (`WeightMaintain3`), a made-up data set based on Lowe et al. (2014, Obesity, 22, 94-100). Overweight participants completed a 12-week weight loss program, then were randomly assigned to one of three weight maintenance conditions:

* None (Control)
* MR (meal replacements): use MR to replace one meal and snack per day
* ED (energy density intervention): book and educational materials on purchasing and preparing foods lower in ED (reducing fat content and/or increasing water content of foods)

Weight was assessed at baseline (start of maintenance), 12 months post, 24 months post, and 36 months post.

(A) Overall, did the participants maintain their weight loss or gain weight?
(B) Did the groups differ in baseline weight change and rate of weight gain (non-maintenance)?
(C) Make a graph of the model fit
(D) Examine the parameter estimates and interpret them

## Exercise 2 Solution

```{r}
load("../data/WeightMaintain3.rda")
summary(WeightMaintain3)
```

(A) Overall, did the participants maintain their weight loss or gain weight?

```{r}
m.null <- lmer(WeightChange ~ 1 + (Assessment | ID), data=WeightMaintain3, REML=F)
m.base <- lmer(WeightChange ~ Assessment + (Assessment | ID), data=WeightMaintain3, REML=F)
anova(m.null, m.base)
```

Yes: $\chi^2(1)=56.5, p << 0.0001$

(B) Did the groups differ in baseline weight change and rate of weight gain (non-maintenance)?
```{r}
m.int <- lmer(WeightChange ~ Assessment + Condition + (Assessment | ID), data=WeightMaintain3, REML=F)
m.full <- lmer(WeightChange ~ Assessment*Condition + (Assessment | ID), data=WeightMaintain3, REML=F)
anova(m.null, m.base, m.int, m.full)
```

Yes: 

*  Baseline: $\chi^2(2)=9.4, p < 0.01$
*  Slope: $\chi^2(2)=40.4, p << 0.0001$

Note: `m.int` is difficult to interpret in light of massive effect on slope

```{r}
coef(summary(m.full))
```

Compared to no intervention, weight (re)gain was 1.75 lbs/year slower for the ED intervention and 0.84 lbs/year slower for the MR intervention.

Note that baseline weight difference parameters are not significantly different from 0.

(C) Make a graph of the model fit
```{r}
ggplot(WeightMaintain3, aes(Assessment, WeightChange, color=Condition)) + 
  stat_summary(fun.data=mean_se, geom="pointrange", size=1) + 
  stat_summary(aes(y=fitted(m.full)), fun.y=mean, geom="line") + 
  theme_bw(base_size=12) + scale_color_manual(values=c("black", "red", "blue"))

ggplot(fortify(m.full), aes(Assessment, WeightChange, color=Condition)) + 
  stat_summary(fun.data=mean_se, geom="pointrange", size=1) + 
  stat_summary(aes(y=.fitted), fun.y=mean, geom="line") + 
  theme_bw(base_size=12) + scale_color_manual(values=c("black", "red", "blue"))
```

(D) Examine the parameter estimates and interpret them

```{r}
round(coef(summary(m.full)), 3)
```

* `(Intercept)` ==> baseline weight change in None group
* `Assessment`  ==> slope of weight change in None group
* `ConditionED` ==> baseline weight change in ED group relative to None group
* `ConditionMR` ==> baseline weight change in MR group relative to None group
* `Assessment:ConditionED`  ==> slope of weight change in ED group relative to None group
* `Assessment:ConditionMR`  ==> slope of weight change in MR groups relative to None group

# Logistic MLR

## Exercise 3
In the `nwl` data set, the participants with aphasia are also separated into two groups based on the general location of their brain lesion: anterior vs. posterior. Compare these two groups:

(A) Is the learning rate (training data) different between these two groups?
(B) Does their test performance differ?
(C) Does their retention from immediate to follow-up test differ?

## Exercise 3 Solution
```{r}
load("../data/nwl.RData")
ggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, 
                                            color=lesion_location, 
                                            shape=lesion_location)) +
  stat_summary(fun.data=mean_se, geom="pointrange") + 
  stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), 
                           fun.y=mean, geom="line") + 
  geom_hline(yintercept=0.5, linetype="dashed") + 
  geom_vline(xintercept=c(7.5, 8.5), linetype="dashed") + 
  scale_x_continuous(breaks=1:9, labels=c(1:7, "Test", "Follow-Up")) + 
  theme_bw(base_size=10) + 
  labs(x="Block", y="Proportion Correct", shape="Lesion\nLocation", color="Lesion\nLocation")
```

(A) Is the learning rate (training data) different between these two groups?
```{r}
m.base <- glmer(cbind(NumCorrect, NumError) ~ block + 
                  (block | ID), 
                data = filter(nwl, block < 8, !is.na(lesion_location)),
                family=binomial)
m.loc0 <- glmer(cbind(NumCorrect, NumError) ~ block + lesion_location + 
                  (block | ID), 
                data=filter(nwl, block < 8, !is.na(lesion_location)),
                family=binomial)
m.loc1 <- glmer(cbind(NumCorrect, NumError) ~ block * lesion_location + 
                  (block | ID), 
                data=filter(nwl, block < 8, !is.na(lesion_location)),
                family=binomial)
#summary(m.loc1)
anova(m.base, m.loc0, m.loc1)
```

(B) Does their test performance differ?
(C) Does their retention from immediate to follow-up test differ?

```{r}
m.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + 
                        (Phase | ID), 
                  data=filter(nwl, block > 7, !is.na(lesion_location)),
                  family="binomial")
summary(m.recall.loc)
```

<!--chapter:end:Lab2_BasicMLR.Rmd-->

---
title: "Lab 03"
author: "Dan Mirman"
output: html_document
---

# Growth Curve Analysis

## Exercise 1

`Az`: Use natural (not orthogonal) polynomials to analyze decline in performance of 30 individuals with probable Alzheimer's disease on three different kinds of tasks - Memory, complex ADL, and simple ADL. 

* Plot the observed data
* (Why are natural polynomials more useful for these data?)
* Prep the data for GCA
* Fit the GCA model(s)
* Interpret the results: 
    + Which terms show significant effects of experimental factors? 
    + To what extent do model comparisons and the parameter-specific p-values yield the same results?
* Plot observed and model fit data

## Exercise 1 Solution

```{r}
library(tidyverse)
library(lme4)
library(effects)
source('../lectures/get_pvalues.R')
source("../lectures/code_poly.R")
load("../data/Az.rda")
summary(Az)
```

Plot the observed data

```{r}
ggplot(Az, aes(Time, Performance, color=Task, fill=Task)) + 
  stat_summary(fun.data=mean_se, geom="ribbon", color=NA, alpha=0.5) +
  stat_summary(fun.y=mean, geom="line")
```

Why are natural polynomials more useful for these data?

* Because it's useful to know whether there are task differences at the starting baseline point

Fit the models

```{r}
# prep for analysis
Az <- code_poly(Az, predictor="Time", poly.order=2, orthogonal=F, draw.poly = F)
# fit the full model
# m.base <- lmer(Performance ~ (poly1 + poly2) + 
#                  (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task), 
#                data=Az, REML=F)
# m.0 <- lmer(Performance ~ (poly1 + poly2) + Task + 
#               (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task), 
#             data=Az, REML=F)
# m.1 <- lmer(Performance ~ poly1*Task + poly2 + 
#               (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task), 
#             data=Az, REML=F)
m.Az.full <- lmer(Performance ~ (poly1 + poly2)*Task + 
                  (poly1 + poly2 | Subject) + (poly1 + poly2 | Subject:Task), 
                data=Az, REML=F)
# anova(m.base, m.0, m.1, m.Az.full)
```

Get p-values
```{r warning=FALSE, message=FALSE}
get_pvalues(m.Az.full)
```
* Intercepts are not different: performance in all tasks starts out the same (thanks, natural polynomials)
* Linear slopes are different: compared to complex ADL tasks, decline in simple ADL tasks is slower and decline in Memory is faster.
* Quadratic term is different for Memory: decline in cADL and sADL tasks is approximately linear, decline in Memory has more curvature (reaching floor?)

Plot model fit
```{r fig.width=6, fig.height=4}
ggplot(Az, aes(Time, Performance, color=Task)) + 
  stat_summary(fun.data=mean_se, geom="pointrange") + 
  stat_summary(fun.y=mean, geom="line", aes(y=fitted(m.Az.full)))
```

## Exercise 2: Logistic GCA

Re-analyze `TargetFix` data using logistic MLR (logistic GCA)

## Exercise 2: Solution
```{r}
load("../data/TargetFix.rda")
#make 3rd-order orth poly
TargetFix <- code_poly(TargetFix, predictor="timeBin", poly.order=3, draw.poly=F)
# fit logisitc GCA model
m.log <- glmer(cbind(sumFix, N-sumFix) ~ (poly1+poly2+poly3)*Condition +
                 (poly1+poly2+poly3 | Subject) +
                 (poly1+poly2 | Subject:Condition),
               data=TargetFix, family=binomial)
summary(m.log)
```

Simpler random effects: note that the correlations between Subject-level random effects are all +1.00 or -1.00, so can simplify the structure by removing them:
```{r}
m.log_zc <- glmer(cbind(sumFix, N-sumFix) ~ (poly1+poly2+poly3)*Condition +
                 (poly1+poly2+poly3 || Subject) +
                 (poly1+poly2 | Subject:Condition),
               data=TargetFix, family=binomial)
summary(m.log_zc)
```

Plot model fit

```{r fig.height=4, fig.width=6}
ggplot(TargetFix, aes(Time, meanFix, color=Condition)) +
  stat_summary(fun.data=mean_se, geom="pointrange") +
  stat_summary(aes(y=fitted(m.log)), fun.y=mean, geom="line") +
  stat_summary(aes(y=fitted(m.log_zc)), fun.y=mean, geom="line", linetype="dashed") +
  theme_bw() + expand_limits(y=c(0,1)) + 
  labs(y="Fixation Proportion", x="Time since word onset (ms)")
```

<!--chapter:end:Lab3_GCA.Rmd-->

