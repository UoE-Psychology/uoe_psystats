```{r, echo=FALSE}
HIDDEN_SOLS=TRUE
set.seed(15732)
ggplot2::theme_set(ggplot2::theme_gray(base_size=13))

library(tidyverse)
```

# Paired T-Test {#chap-paired-t-test}


<div class="lo">
#### Instructions {-}
  
- In this two-hour lab we will go through worked examples in the first hour, and you will attempt to answer some questions in the second hour.
- The Rmarkdown file for this week is [here](https://uoe-psychology.github.io/uoe_psystats/dapr1/labsheets/week_18_practice.Rmd).


#### Learning outcomes {-}

**LO1.** Understand how to perform a paired-sample $t$-test and interpret the results.

**LO2.** effect size blah blah

<!-- #### Reading {-} -->

</div>

## Recap {-}


Last week we extended our understanding of the $t$-test to compare the means of two populations (or the means of two treatment groups, if doing a randomized experiment).  
We therefore now have the tools to answer questions of the form:  
  
1. _is_ [population mean] _different from_ [hypothesised value] _?_ (one sample $t$-test)  
2. _is_ [population mean 1] _different from_ [population mean 2] _?_ (independent samples $t$-test)  
2a. _is the mean of_ [variable] _different between_ [group-1 and group-2] _?_ (independent samples $t$-test)  


#### One sample $t$-test ([Week 16](#chap-one-mean-test)) {-}
<center>
$$
t = \frac{\bar{x} - \mu_0}{SE(\bar{x})}, \qquad SE(\bar{x}) = \frac{s}{\sqrt{n}}
$$
</center>
__Validity conditions:__  
i. The data are continuous (not discrete).  
ii. The quantitative variable of interest is normally distributed in the population OR the sample size is large enough (as a convention, $n \geq 20$) and the data are not strongly skewed.  
iii. The data are randomly sampled from a population.  


---

#### Two independent samples $t$-test (with equal variances) ([Week 17](#two-indep-samples)) {-}  
$$
t = \frac{\bar x_1 - \bar x_2}{SE(\bar x_1 - \bar x_2)}, \qquad SE(\bar{x}_1 - \bar{x}_2) = S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}, \qquad S_p = \sqrt\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}
$$
__Validity conditions:__  
i. The data are continuous (not discrete).  
ii. The quantitative variable of interest is normally distributed in both populations OR both sample sizes are large (as a convention, $n_1 \geq 20$ and $n_2 \geq 20$) and the sample distributions should not be strongly skewed.  
iii. Independence of observations within and across groups.  
iv. Homogeneity of variance across groups.  

We also learnt that when the response variable does __not__ have equal variance across groups, we could use the Welch-Satterthwaite approximation to the degrees of freedom, and set `var.equal=FALSE` in the `t.test()` function.  


## Paired $t$-test {-}

The last $t$-test we are going to learn about is the paired $t$-test, or 'dependent samples $t$-test'. 
Recall that last week we were concerned with evaluating the differences in means between two groups, and one of our assumptions in conducting our test was that the two groups were independent.  
However, we are often interested in asking whether there is a difference in means between two groups which are _dependent_.  


We say that two sets of observations $A$ and $B$ are _dependent_ when there is some pairing in the sets, such that $A_1$ is linked to $B_1$ in the same way that $A_2$ is linked to $B_2$, and so on.

<div class="noteBox">
__Pairs of time points:__ Same person, same variable, different times  
```{r echo=FALSE}
tibble(
  subject = c("sub1","sub2","..."),
  time_1 = c(25, 18, "..."),
  time_2 = c(25, 19, "...")
) %>% knitr::kable()
```
__Pairs of variables:__ Same person, different variables  
```{r echo=FALSE}
tibble(
  subject = c("sub1","sub2","..."),
  maths_test = c(42, 46, "..."),
  english_test = c(38, 40, "...")
) %>% knitr::kable()
```
__Pairs of people:__ Same variable, different individual from a dyad (pair of people)
`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
Do employees work different amount of hours to their bosses?  
+ Same variable: hours per day  
+ Different person: employee vs boss  
```{r echo=FALSE}
tibble(
  pair = c("pair1","pair2","..."),
  line_manager_hours = c(10, 8, "..."),
  employee_hours = c(9, 9, "...")
) %>% knitr::kable()
```
`r msmbstyle::solution_end()`


</div>

<div class="red">
#### Comparing the means of two dependent groups {-}

Suppose you wish to determine whether the mean difference between two dependent sets of observations is zero, and if the difference is significant, you wish to quantify the magnitude of the difference using a confidence interval.  

 


##### Test of significance  {-}


Null hypothesis    
The null hypothesis assumes that the true mean difference ($\mu_d$) is equal to zero.

$H_0: \mu_d = 0$  

Alternative hypothesis.
The alternative hypothesis assumes that $\mu_d$ is less than/greater than/not equal to zero.  

i. $H_1: \mu_d < 0$  (lower-tailed)
ii. $H_1: \mu_d > 0$  (lower-tailed)
iii. $H_1: \mu_d \neq 0$  (two-tailed)


Test statistic:
<center>
$$
t = \frac{\bar{d} - 0}{SE(\bar{d})}, \qquad SE(\bar{d})= \frac{s_d}{\sqrt{n}}
$$
</center>


$p$-value:

i. $\mathrm{Pr}(T_{df} \leq t)$
ii. $\mathrm{Pr}(T_{df} \geq t)$
iii. $2 \times \mathrm{Pr}(T_{df} \leq |t|)$

where $T_{df}$ denotes a $t$-distribution with $df$ degrees of freedom.



</center>

##### Confidence interval for $\mu_d - 0$ {-}

<center>
$$
(\bar d) \pm t^*_{df} \times SE(\bar d)
$$
</center>
where $t^*_{df}$ denotes the critical value corresponding to a desired $\alpha$ level for a $t$-distribution with $df$ degrees of freedom.


##### Validity conditions {-}

These above procedures are considered valid if:

- The sample data arise from independent random samples from two populations OR from random assignment of the units to treatment groups.
- Either the quantitative variable of interest is normally distributed in both populations OR both sample sizes are large (as a convention, $n_1 \geq 20$ and $n_2 \geq 20$) and the sample distributions should not be strongly skewed.

</div>


















paired samples t test 
$$
t = \frac{\bar{d} - 0}{\frac{s_d}{\sqrt{n}}} = \frac{\bar{d} - 0}{SE(\bar{d})}
$$

Where $d$ is the difference between pairs $d = x_1 - x_2$,  
$\bar{d}$ is the mean of the differences,  
and $s_d$ is the standard deviation of the differences.  

With the one sample t test, the steps we do are:

1. calculate the sample mean
1. calculate the sample standard deviation 
1. calculate t
1. calculate the probability of observing a t statistic at least as extreme assuming the null hypothesis to be true. 

With the paired sample t test, the steps we are:

**0. calculate the difference in pairs**
1. calculate the sample mean **difference**
1. calculate the sample standard deviation **of differences**
1. calculate t
1. calculate the probability of observing a t statistic at least as extreme assuming the null hypothesis to be true. 


and it's that easy! the remainder is the same as we did in [Week 16](#chap-one-mean-test).


## Walkthrough 


- scores on ACE-III 
The Addenbrooke's Cognitive Examination-III (ACE-III) is a brief cognitive test that assesses five cognitive domains: attention, memory, verbal fluency, language and visuospatial abilities. ... The total score is 100 with higher scores indicating better cognitive functioning

q - how is the data paired?
a - same person, same variable, different time points

q hypotheses?

q - make a new column of the difference in scores between time points  
a - mutate(diff = t2-t1)

q - calculate $\bar{x}_d$ and $s_d$.  
a - summarise(mean(diff), sd(diff))

q - fill in blanks t-statistic 

q - calculate t in r

q - calculate pr(t)  

q - how would we report this? t(df) = , p </>/= ?


## ALL IN ONE LINE OF CODE! {-}

q - run ?t.test. what might be the argument we need to use for this test?  
a - paired = TRUE  



## Assumptions {-}  

 The dependent variable must be continuous (interval/ratio).
• The observations are independent of one another.
• The dependent variable should be approximately normally distributed.
• The dependent variable should not contain any outliers.


## Summary  



## Lab  
  
_Please attempt the questions **before** looking at the solutions. Copy & pasting the solutions will not help with learning!_  



data - age differences in heterosexual marriages
[here](http://www.lock5stat.com/datasets/MarriageAges.txt)
```{r}
marriages<-read.table("http://www.lock5stat.com/datasets/MarriageAges.txt", header = TRUE)
```


q - add new column which is the husband's age minus the wife's age
```{r}
marriages <- marriages %>% 
  mutate(
    agediff = Husband - Wife
  )


```


q - think. if we get a positive t statistic, t>0, what direction is the difference? who tends to be older than who? 
a - because we did husband minus wife, a positive t statistic indicates men tend to be older than women in heterosexual marriages. 

q - following the procedure we learnt in week 16, calculate the t statistic manually. 

```{r}
terms <- marriages %>% 
  summarise(
    xbar = mean(agediff),
    s = sd(agediff),
    mu_0 = 0,
    n = n()
  )

t = (terms$xbar - terms$mu_0) / (terms$s / sqrt(terms$n))
t
```



data - school students preference for math vs preference for english  

data - scores pre and post intervention  

data - practice effects. 














### Glossary  
