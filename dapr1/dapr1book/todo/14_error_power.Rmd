```{r, echo=FALSE, message=FALSE}
HIDDEN_SOLS=FALSE
set.seed(15732)
ggplot2::theme_set(ggplot2::theme_gray(base_size=13))

library(tidyverse)
library(moderndive)
```

# Type I and Type II Errors, Power! {#chap-typeerror}


<div class="lo">
#### Instructions {-}
  
- In this two-hour lab we will go through worked examples in the first hour, and you will attempt to answer some questions in the second hour.
- The Rmarkdown file for this week is [here](https://uoe-psychology.github.io/uoe_psystats/dapr1/labsheets/week_14_practice.Rmd).


#### Learning outcomes {-}

**LO1.** Recap hypothesis testing 

**LO2.** Understand the different types of errors 

**LO3.** Introduce statistical power  


#### Reading {-}

?????????????????????

</div>


## Recap


1. random chance
1. alternative explanation
1. statistical hypothesis HoHa!
1. from random chance model, we constructed a null distribution.(lab involved bootstrapping the null)
1. compare observed statistic to null distribution
1. retrieved p-value (proportion of null distribution at least as extreme as observed)
1. made a formal decision.


## Walkthrough

### Example 1: Coin flip {-}    

<div style="background-image: url('flipping.jpg')">
#### Research Question & Hypotheses {-}

Is our coin biased? 
<br><br>
*Null hypothesis*: We're just as likely to get heads as tails when we flip the coin.
$$H_0: p = 0.5$$
*Alternative hypothesis*: We're more likely to see either heads or tails when we flip the coin.
$$H_1: p \neq 0.5$$

#### Data collection {-} 

We flip the coin 90 times, and it lands on heads 55 times. 
</div>

#### Analysis {-}  

<div class="red">
<br>
**Steps**
<br> 

1. Calculate our statistic  
1. Generate the null distribution  
1. Calculate the probability of seeing our statistic (or one which is farther away from the null) if the null were true (this is the p-value)  

</div>  

**1. Calculate our statistic, $\hat{p}$**  
```{r}
p_hat <- 55/90
p_hat
```


**2. Generate the null distribution**  

<div class="noteBox">
Remember that the null distribution is what we would expect if the null hypothesis were true - it is how much the statistics computed from samples of size $n$ would vary if the null is true. In our case, this quantifies how much our statistic (the proportion of heads) in a sample of size 90 would vary if the true probability of the coin landing on heads were 1/2.
</div>

```{r warning=FALSE, message=FALSE}
# Specify our possible outcomes and their probabilities under the null
outcomes <- tibble(vals = factor(c('Heads', 'Tails')))
prob <- c(1/2, 1/2)

# generate samples under the null
samples <- rep_sample_n(outcomes, size = 90, replace = TRUE, reps = 1000, prob = prob)

# calculate the statistics for each sample to create the null distribution
null_distribution <- samples %>% 
  group_by(replicate) %>%
  summarise(prop = sum(vals == 'Heads') / n())

# plot the null distribution  
ggplot(null_distribution, aes(x = prop)) +
  geom_dotplot(binwidth = 0.01, dotsize = 0.5, fill = 'white', stackratio = 0.5) +
  labs(x = expr(hat(p)))
```

And plot the observed statistic on top, like we did last week. 

```{r}
ggplot(null_distribution, aes(x = prop, fill = (prop >= 0.61))) +
  geom_dotplot(binwidth = 0.01, dotsize = 0.5, stackratio = 0.5) +
  scale_fill_manual(values = c('white', 'tomato1')) +
  geom_vline(xintercept = 0.61, color = 'tomato1', size = 1) +
  labs(x = expr(hat(p)), fill = expr(hat(p) >= 0.61))
```

**3. Calculate our p-value**  
<br>
How surprising is 55 of 90 coin flips? We can compare it against the null distribution.

`r msmbstyle::question_begin()`
What is our p-value?   

1. The proportion of the null distribution which is $\geq0.61$
1. The proportion of the null distribution which is $\geq0.61$ or $\leq0.39$  
1. 2 times the proportion of the null distribution which is $\geq0.61$ or $\leq0.39$ (whichever is smallest)  

`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
If we perform an hypothesis test for the two-sided alternative $p \neq 0.5$, we compute it as twice the proportion in the smallest tail, i.e. the tail with the smallest count.
```{r}
pvalue <- null_distribution %>%
  summarise(
    pvalue_lefttail = sum(prop <= 0.39) / n(),
    pvalue_righttail = sum(prop >= 0.61) / n()
  )

pvalue

0.018 * 2
```
`r msmbstyle::solution_end()`


`r msmbstyle::question_begin()`
What is our formal decision about our hypotheses? 

1. Not enough evidence to reject $H_0$<br>($H_0:$ We're just as likely to get heads as tails when we flip the coin.)
1. Evidence in favour of $H_1$<br>($H_1:$ We're more likely to see either heads or tails when we flip the coin.)

`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
According to our p-value, we have reason to reject the null hypothesis that our coin will land on heads and tails equally often. 
`r msmbstyle::solution_end()`

### An analogy {-}

Might we have made a mistake here? Is 55 out of 90 coin flips *surprising enough* for us to reject the hypothesis that the coin is fair?  
<br>
Last week we discussed an analogy in law, in which a person on trial is presumed innocent until proven guilty. Similarly, we presume $H_0$ to be true until there is strong evidence to reject it. How strong must the evidence be? How do we avoid wrongly convicting an innocent person? (i.e., wrongly rejecting an hypothesis which is actually true?)  


### Two different types of errors {-}

|                      | Person is innocent     | Person is guilty         |
|:---------------------|:----------------------:|:------------------------:|
|Verdict = Innocent    | Correct decision       | Criminal goes free       |
|Verdict =  Guilty     | Wrongful conviction    | Correct decision         |
  
  
|                          | $H_0$ is True          | $H_0$ is False             |
|:-------------------------|:----------------------:|:--------------------------:|
|Test doesn't reject $H_0$ | Correct                | Type II Error<br>($\beta$) |
|Test rejects $H_0$        | Type I Error<br>($\alpha$)| Correct                 |

### Type I errors {-}  

If the null hypothesis is true, then the **sampling distribution** of our statistic follows the null distribution which we constructed above, and we will reject (incorrectly) any sample statistic which results in a p-value which is less than or equal to our $\alpha$ level (e.g., the 0.05 we set earlier). 
<br>
So the probability of making this error is equal to the $alpha$ level which we set.  
<br>
In other words, when the null hypothesis is true, 0.05 (or 5%) of the random samples we could take would result in us rejecting it.   

<div class="noteBox"> 
#### A thought experiment {-} 

+ there are 20 researchers. 
+ each researcher has a perfectly balanced/fair coin.  
+ each researcher conducts a statistical test at $\alpha = 0.05$ to evaluate whether their coin is fair (lands on heads equally as often as it lands on tails).

`r msmbstyle::question_begin()`
How many of the researchers' tests would we expect to result in a type I error?  
<small>**Remember:** The probability of making a Type I error is the probability of getting an unlikely sample statistic simply due to chance sampling variation (i.e., we just happen to get a random sample with an unlikely statistic).</small>
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`

This is similar to asking "What is the probability of observing at least one significant result due to chance sampling variation alone?". We can work this out..
<br>  

+ The probabilty of 1 researcher getting a non-significant result (p-value $> 0.05$) assuming the null hypothesis is true is 1 minus the probability of them getting a significant result (p-value $\leq 0.05$).<br>$1 - 0.05 = 0.95$.
+ If there are 20 researchers, the probability of them *all* getting non-significant results when their nulls are all true is $0.95^{20} = 0.358$
+ Conversely, the probability that at least one of them gets a significant result even though all their nulls are true is $1 - 0.358 = 0.642$  

`r msmbstyle::solution_end()`
</div>

### Type II errors and Power {-}

A type II error is denoted by $\beta$. <br>
This happens when $H_0$ is false, but we do not have enough evidence to reject it.  
  

In our table, the columns specify the possible states of the world ($H_0$ is either True or False).   
In each of these possible worlds, there....

<!-- need something about probability summing to one in each possible world -->


<br>
In each of the possible states of the world, there are two potential outcomes of conducting a statistical test (Reject $H-0$ or Don't reject $H_0$).  
<br>
We have seen that *if $H_0$ is true*, then the probability of incorrectly rejecting $H_0$ is $\alpha$.  
We have seen that *if $H_0$ is false*, then the probability of incorrectly failing to reject $H_0$ is $\beta$.  
Conversely, the probability of *correctly rejecting $H_0$* is $1-\beta$, and this is known as the **statistical power** of our test.  

|                          | $H_0$ is True          | $H_0$ is False             |
|:-------------------------|:----------------------:|:--------------------------:|
|Test doesn't reject $H_0$ | Correct<br>**1-$\alpha$**  | Type II Error<br>($\beta$) |
|Test rejects $H_0$        | Type I Error<br>($\alpha$)| Correct<br>**1-$\beta$**<br>**Power**|

<div class="def">
#### Statistical power {-}

Statistical power is the probability of a hypothesis test of finding an effect if there is an effect to be found.
</div> 

### Example 2: A biased coin {-}

I have a trick coin which is weighted so that it lands on heads 60% of the time (rather than the usual 50% for everyday fair coins). 
<br>
Oh no! Umberto has noticed that whenever we flip a coin I call heads, and I often seem to win. He accuses me of cheating by using a trick coin!
I make him an offer: he can flip the coin 50 times in order to decide whether or not it really is a trick coin. 

`r msmbstyle::question_begin()`
In Umberto's 50 coin flips, what proportion of heads would lead him to the correct conclusion that the coin is a trick coin?
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
If Umberto flips the coin 50 times, under the null hypothesis, he would need to get a sample statistic ($\hat{p}$) of .64 or greater 
```{r message=FALSE,warning=FALSE}
# Specify our possible outcomes and their probabilities under the null
outcomes <- tibble(vals = factor(c('Heads', 'Tails')))
prob <- c(1/2, 1/2)

# generate samples under the null
samples <- rep_sample_n(outcomes, size = 50, replace = TRUE, reps = 1000, prob = prob)

# calculate the statistics for each sample to create the null distribution
null_distribution <- samples %>% 
  group_by(replicate) %>%
  summarise(prop = sum(vals == 'Heads') / n())

null_distribution <- null_distribution %>%
  arrange(prop) %>%
  mutate(idx = 1:n())

# plot the null distribution
ggplot(null_distribution, aes(x = prop, fill = (idx >= 950))) + 
  geom_dotplot(binwidth = 0.01, dotsize = 0.5, stackratio = 0.5) +
  scale_fill_manual(values = c('white', 'tomato1')) +
  labs(x = expr(hat(p)))

null_distribution %>%
  filter(idx == 950)
```
`r msmbstyle::solution_end()`

Things we know so far:  

+ The coin is rigged to land on heads on 60% of flips - the true probability of heads is 0.6. 
+ If 62% or more of Umberto's 50 coin flips come up heads, then he will reject his null hypothesis (that the coin is fair)


`r msmbstyle::question_begin()`
What's the probability that Umberto's 50 flips will come up with 64% or more heads?
<br>
In other words, what is the power of his test?
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
We can actually generate the true sampling distribution because we know the true parameter (i.e., we know that the coin lands on heads 60% of the time).
```{r message=FALSE, warning=FALSE}
outcomes <- tibble(vals = factor(c('Heads', 'Tails')))
prob <- c(0.6, 0.4)

samples <- rep_sample_n(outcomes, size = 50, replace = TRUE, reps = 1000, prob = prob)

# calculate the statistics for each sample to create the null distribution
alternative_distribution <- samples %>% 
  group_by(replicate) %>%
  summarise(prop = sum(vals == 'Heads') / n())

alternative_distribution %>%
  summarise(
    prob_crit = sum(prop >= 0.62) / n()
  )

```
`r msmbstyle::solution_end()`

### Generalising it {-} 

1. When we conduct NHST, we set $\alpha$.  
1. In setting $\alpha$, we define a **critical region** under the null distribution. The **critical value** is the value of the statistic which defines the start of this region. Any statistic more extreme than this will result in rejecting the null hypothesis.
1. If the null hypothesis is false, the probability that we reject the null hypothesis depends on a) how far away from the null hypothesis the true state of the world is, and b) our sample size. 
1. For a given **effect size** (i.e., difference from the null hypothesis), we can compute the power of a test based on a given sample size. This corresponds to the probability of getting a statistic more extreme than the critical value, given a theorised effect size (i.e., a theorised alternative distribution)

### Overlapping distributions {-}

Talk through applet

https://istats.shinyapps.io/power/
https://rpsychologist.com/d3/NHST/ 

### In-class activity



---

## Lab

Q1 - if my trick coin was actually weighted so that it landed on heads 75% of the time, what would the power of Umberto's test be? 


<div class="red">
For a given **effect size** (i.e., difference from the null hypothesis), we can compute the power of a test based on a given sample size.
However....
we can also decide on what we want the power of a test to be, and ask what the minimum sample size is that is needed to detect a given effect size.
</div>

Q2.- how many coin flips should Umberto do in order to increase his power to 80%?
A haven't thought about this yet :)


