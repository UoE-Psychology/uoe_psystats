```{r, echo=FALSE, message=FALSE}
HIDDEN_SOLS=FALSE
set.seed(15732)
ggplot2::theme_set(ggplot2::theme_gray(base_size=13))

library(tidyverse)
library(moderndive)
```

# Type I and Type II Errors, Power! {#chap-typeerror}


<div class="lo">
#### Instructions {-}
  
- In this two-hour lab we will go through worked examples in the first hour, and you will attempt to answer some questions in the second hour.
- The Rmarkdown file for this week is [here](https://uoe-psychology.github.io/uoe_psystats/dapr1/labsheets/week_14_practice.Rmd).


#### Learning outcomes {-}

**LO1.** Recap hypothesis testing 

**LO2.** Understand the different types of errors 

**LO3.** Introduce statistical power  


#### Reading {-}

?????????????????????

</div>


## Recap


1. random chance
1. alternative explanation
1. statistical hypothesis HoHa!
1. from random chance model, we constructed a null distribution.(lab involved bootstrapping the null)
1. compare observed statistic to null distribution
1. retrieved p-value (proportion of null distribution at least as extreme as observed)
1. made a formal decision.


## Walkthrough

### Example 1: Coin toss {-}    

<div style="background-image: url('flipping.jpg')">
#### Research Question & Hypotheses {-}

Is our coin biased? 
<br><br>
*Null hypothesis*: We're just as likely to get heads as tails when we flip the coin.
$$H_0: p_{heads} = 0.5$$
*Alternative hypothesis*: We're more likely to see either heads or tails when we flip the coin.
$$H_1: p_{heads} \neq 0.5$$

#### Data collection {-} 

We toss the coin 90 times, and it lands on heads 54 times. 
</div>

#### Analysis {-}  

<div class="red">
<br>
**Steps**
<br> 

1. Calculate our statistic  
1. Generate the null distribution  
1. Calculate the probability of seeing our statistic (or one which is more extremely different the null) if the null were true (the p-value)  

</div>  

1. Calculate our statistic, $\hat{p}$  
```{r}
p_hat <- 55/90
p_hat
```


2. Generate the null distribution  

Is our 54 of 90 coin tosses that surprising?<br>
Let's compare it against the null distribution.<br>
Remember that the null distribution is what we would expect if the null hypothesis were true - it is how much the statistics computed from samples of size $n$ would vary if the null is true. In our case, this quantifies how much our statistic (the proportion of heads) in a sample of size 90 would vary if the true probability of the coin landing on heads were 1/2.

```{r warning=FALSE, message=FALSE}
# Specify our possible outcomes and their probabilities under the null
outcomes <- tibble(vals = factor(c('Heads', 'Tails')))
prob <- c(1/2, 1/2)

# generate samples under the null
samples <- rep_sample_n(outcomes, size = 90, replace = TRUE, reps = 1000, prob = prob)

# calculate the statistics for each sample to create the null distribution
null_distribution <- samples %>% 
  group_by(replicate) %>%
  summarise(prop = sum(vals == 'Heads') / n())

# plot the null distribution  
ggplot(null_distribution, aes(x = prop)) +
  geom_dotplot(binwidth = 0.01, dotsize = 0.5, fill = 'white', stackratio = 0.5) +
  labs(x = expr(hat(p)))
```

And plot the observed statistic on top, like we did last week. 

```{r}
ggplot(null_distribution, aes(x = prop, fill = (prop >= 0.61))) +
  geom_dotplot(binwidth = 0.01, dotsize = 0.5, stackratio = 0.5) +
  scale_fill_manual(values = c('white', 'tomato1')) +
  geom_vline(xintercept = 0.61, color = 'tomato1', size = 1) +
  labs(x = expr(hat(p)), fill = expr(hat(p) >= 0.61))
```

3. Calculate our p-value

`r msmbstyle::question_begin()`
What is our p-value?   

1. The proportion of the null distribution which is $\geq0.61$
1. The proportion of the null distribution which is $\geq0.61$ or $\leq0.39$  
1. 2 times the proportion of the null distribution which is $\geq0.61$ or $\leq0.39$ (whichever is smallest)  

`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
if we perform an hypothesis test for the two-sided alternative $p \neq ...$, we compute it as twice the proportion in the smallest tail, i.e. the tail with the smallest count.
```{r}
pvalue <- null_distribution %>%
  summarise(
    pvalue_lefttail = sum(prop <= 0.39) / n(),
    pvalue_righttail = sum(prop >= 0.61) / n()
  )

pvalue

0.018 * 2
```
`r msmbstyle::solution_end()`


`r msmbstyle::question_begin()`
What is our formal decision about our hypotheses? 

1. Not enough evidence to reject $H_0$ ($H_0:$ We're just as likely to get heads as tails when we flip the coin.)
1. Evidence in favour of $H_1$ ($H_1:$ We're more likely to see either heads or tails when we flip the coin.)

`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
According to our p-value, we have reason to reject the null hypothesis that our coin will land on heads and tails equally often. 
`r msmbstyle::solution_end()`

### An analogy {-}

Have we made an mistake here?
<br>
Is 55 out of 90 coin tosses *that* surprising? 

Last week we discussed an analogy in law, in which a person on trial is presumed innocent until proven guilty. Similarly, we presume $H_0$ to be true until there is strong evidence to reject it. 
<br>
How strong must the evidence be? Have we just wrongly convicted an innocent person? (i.e., wrongly rejected an hypothesis which is actually true?)


### Two different types of errors {-}

|                      | Person is innocent     | Person is guilty         |
|:---------------------|:----------------------:|:------------------------:|
|Verdict = Innocent    | Correct decision       | Criminal goes free       |
|Verdict =  Guilty     | Wrongful conviction    | Correct decision         |

|                          | $H_0$ is True          | $H_0$ is False             |
|:-------------------------|:----------------------:|:--------------------------:|
|Test doesn't reject $H_0$ | Correct                | Type II Error<br>($\beta$) |
|Test rejects $H_0$        | Type I Error<br>($\alpha$)| Correct                 |

### Type I errors {-}  

*if* the null hypothesis is true, then the sampling distribution of our statistic is the null distribution (plotted above), and we will reject (incorrectly) any sample statistic which results in a p-value which is less than or equal to our $\alpha$ level (e.g., the 0.05 we set earlier). 
<br>
So the probability of making this error is equal to the $alpha$ level which we set. 

<div class="noteBox"> 
#### A thought experiment {-} 

+ there are 20 researchers. 
+ each researcher has a perfectly balanced/fair coin.  
+ each researcher conducts a statistical test at $\alpha = 0.05$ to evaluate whether their coin is fair (lands on heads equally as often as it lands on tails).

`r msmbstyle::question_begin()`
How many of the researchers' tests would we expect to result in a type I error?  
<small>**Remember:** The probability of making a Type I error is the probability of getting an unlikely sample statistic simply due to chance sampling variation (i.e., we just happen to get a random sample with an unlikely statistic).</small>
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`

`r msmbstyle::solution_end()`
</div>

### Type II errors {-}


Q what are our ideal values for alpha and beta? 
A 0 and 0. 
BUT, this isn't possible when we sample



### Exploration

Talk through applet

https://istats.shinyapps.io/power/


### In-class activity


option... decrease alpha!
div think - what are we doing here? we making the probability of convicting an innocent person much less likely 
casually - we've got to get some *really strong evidence* that they're guilty. 

### Example 2: ??

on the other hand...
research Q: is global temperature rising? 
H_o, temperature in y1 == temperature y2
H_a temperature in y1 != temperature y2
do a test, 
get a p-value <.01
with our new alpha of .001, we don't reject H_o. 
But maybe we're being to strict! 
Now we are letting a guilty person walk free!


---

## Lab



