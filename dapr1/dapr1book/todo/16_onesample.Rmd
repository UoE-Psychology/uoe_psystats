```{r, echo=FALSE}
HIDDEN_SOLS=FALSE
set.seed(15732)
ggplot2::theme_set(ggplot2::theme_gray(base_size=13))

library(tidyverse)
```

# One Sample Mean


<div class="lo">
#### Instructions {-}
  
- In this two-hour lab we will go through worked examples in the first hour, and you will attempt to answer some questions in the second hour.
- The Rmarkdown file for this week is [here](https://uoe-psychology.github.io/uoe_psystats/dapr1/labsheets/week_16_practice.Rmd).


#### Learning outcomes {-}

**LO1.** 

**LO2.** 

#### Reading {-}


</div>


## Recap


- sampling, sampling distribution
- hypothesis testing
- relies on sampling distribution. we saw in several weeks how to generate sampling distributions
- last week, we saw how we could also do things theoretically, assuming a shape, and using a formula
- this all about standard error (i.e. how much our statistic varies between samples). 
  - with NFL, we took lots of samples to see how their mean salaries varied (week 11) - (sampling many times from population)
  - we then looked at how we could use bootstrapping to approximate this (week 12) - (*re*sampling many times from the original sample)
  - finally, we saw how we could do it theoretically - just one sample, assume a shape, use a formula
  - SE = SD of bootstrap distribution, = sigma/sqrt(n)

we can't do 1 (unless we actually take lots of samples from a population), but we can do 2 (with a computer) or 3 (by hand, or simple calculator).

- this is really important - we've got two ways of doing things now:
1- traditional, theoretical way, assuming SE = sigma/sqrt(n). assumes normal shaped sampling dist
2- computationally heavy, simulated way. bootstrap SE



## Walkthrough  

questions
- is the average body temperature 37 degrees C
- if the norm for a cognitive test is ---, are dapr1 students significantly different?
- On the Bedeck Depression Inventory (BDI), a score >25 is considered clinical diagnosis of depression. is the average score of people with --- significantly above this cutoff?


hypotheses:

null hypothesis - the population mean is equal to some prespecified value $\mu_0$. 
$H_0: \mu = \mu_0$

alternative hypothesis - the population mean is not equal to/less than/greater than some prespecified value $\mu_0$. 
$H_1: \mu \neq \mu_0$
$H_1: \mu < \mu_0$
$H_1: \mu > \mu_0$


example 1 

question - ??
we have data on our entire population. 

test the hypothesis.
- are we making a statistical inference here? 
- no, we're actually just asking a question about a population which we can directly answer because we have data on the entire population. remember that inferencing is when we use sample statistics to make claims about a population parameter.  

$\mu = 35?$
$30 = 35?$

example 2 -??

we have a sample of .--, 

our hypothesis is about $\mu$. the population parameter.
$\mu = ..$

but instead of directly calculating $\mu$, we have to use our sample statistic $\bar{x}$ (the mean of our sample) as our best estimate.  

this brings uncertainty. we don't know how good $\bar{x}$ is as an estimate of $\mu$. 


we need to know standard error - remember that the standard error reflects how much means from random samples of -- will vary. 

why?
well, imagine the following scenario: 
population mean is 20, have a sample of 50, for which the standard error of the mean is 2. 
- if we take lots of samples of size 50, some would have mean 16, some 22. 95% of the samples we take will have a mean between 16 and 24 (rounded up from 1.96*SE)
- remember that the standard error is the standard deviation of the sampling distribution.  


now lets imagine we are testing $H_0: \mu = 20$
we have a sample of 50, and the mean is 23. 
23-20 = 3
is this difference big enough? 
by dividing this difference by the standard error, we get an idea how big this distance is (from xbar to 20) in terms of standard deviations of the sampling distribution. 

(23-20)/2 = 3/2 = 1.5 
so this 1.5 refers to distance from our sample mean and our null parameter, in terms of the spread of the sample means 










we can't actually sample lots of times from the population in order to find the standard error. 
remember what we can do? we can either
- resample with replacement (bootstrap) to find an estimate of the SE
- use our formula se = sigma/sqrt(n)







- 

- bootstrapping

- traditional 

- comparison


- random variables (T when null is true looks like ...)
- our question "how surprising is bar(x)?" is now turned into "how surprising is T?". 
- df






### In-class activity





---

## Lab



