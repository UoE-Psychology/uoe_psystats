--- 
title: "Data Analysis for Psychology in R (dapR1) - Labs"
author: "Department of Psychology, University of Edinburgh"
date: " 2019-2020"
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    includes:
      in_header: logo.html
    config:
      toc:
        collapse: section
      sharing:
        facebook: false
        twitter: false
documentclass: book
github-repo: rstudio/bookdown-demo
description: "This is the page that contains the course labs materials"
---

# Overview of the Course{-}

Placeholder


#### SEMESTER 1 {-}
#### SEMESTER 2 {-}
## The team{-}
## R Cheatsheets{-}
## R Community{-}

<!--chapter:end:index.Rmd-->


# Week 1{}

Placeholder


## Introduction to R and RStudio
## Install the recent version of R and R Studio
### First Step 
### Second Step
## Getting Started in RStudio
## R as an interactive environment
## Check your settings
### Disable automatic saving of your workspace
### Adjust fonts/colours if you like
## Setting Up Your Working Directory 
## The Console
## Spacing
## Typos
## Unfinishe.... d
## Basic Arithmetic 
## Using Functions for Calculations
## R Scripts
## Short Example 
## Naming variables
## Now over to you
### Exercise 1
### Exercise 2
## Solutions

<!--chapter:end:01_Week_1.Rmd-->


# Week 2 {}

Placeholder


## Introduction to RMarkdown
##  What is R Markdown?
## Getting things ready
## R Markdown basics
## Headings
## Text
##  Tables
## Lists
### Unordered 
### Ordered
##  Rmd documents
## Code chunks
## Common Code Chunks Options
## Including images or links
### Adding links
### Adding figures & pictures
## Generating documents
## Extra: Open/Save files on Rstudio Cloud  (Chrome users)

<!--chapter:end:02_Week_2.Rmd-->


# Week 3 {}

Placeholder


## Vectors, lists, data frames and data types
## Get the package first
## Numeric Data
## Text/Character Data
## Logical Data
## Variable Classes 
## Factors
## Lists
## Practice.Rmd Solutions 
### Exercise 1
### Exercise 2
### Exercise 3

<!--chapter:end:03_Week_3.Rmd-->


# Week 4 {}

Placeholder


## Introduction to plots & geoms (ggplot)
## Visualisations
## Get our data sorted
## Numerical data
## Simple one-variable plot using ggplot()
### Continuous variable
## Categorical variables
## Continuous variables grouped by a categorical one
## Even more advanced
## Practice.Rmd Solutions
### Exercise 1
### Exercise 2 
### Exercise 3 -  Advanced 

<!--chapter:end:04_Week_4.Rmd-->


# Week 5{} 

Placeholder


## Central Tendency and Variability
## Load all the necessary packages
## Descriptive Statistics
## Central tendency & variability 
## Mean and median 
### Reading data in
## Using piping operator for descriptive statistics
### Mean
### Median
## Standard deviation
## Visualise your data
## Practice.Rmd Solutions
###  Income Distribution Example
### Visualisations 
#### Visualise the distribution of income 
#### Visualise the distribution of income by region

<!--chapter:end:05_Week_5.Rmd-->


# Week 6{}

Placeholder


## Plotting Functions and Simple Data Transformation
## Load all the necessary packages
## Part 1: Hand plotting functions 
## Basics 
## Linear functions
### Tree height example
### Non-linear functions (first order polynomials)
## Practice plotting
## Part 2: Introduction to Data Transformation
## Renaming
## Adding new variables
## Transformation and skewness
## Mean Centering
##  Standardisation
## Practice.Rmd Solutions

<!--chapter:end:06_Week_6.Rmd-->


# Week 7 {}

Placeholder


## Reading in Data, Merge and More R Practice
## Dataset 1 (.csv)
## Dataset 2 (.txt)
## Dataset 3 (.sav and .dta)
## Merging datasets together
## Sorting and arrange()
## Data description
## Using filter()
## Visualisations
## Save the file in your folder
## Practice.Rmd Solutions

<!--chapter:end:07_Week_7.Rmd-->


# Week 8 {}

Placeholder


## Introduction to Probability 
## Example 1 (hot hand)
## Example 2 (coin toss)
## Example 3 (Independent shooter)
## Practice  Rmd. Solutions
### Sex of the babies  born in the UK
## Pen and Paper Exercises
### Boys and girls paradox  (Mr. Jones and Mr. Smith)
### Rugby captain
### Answers
### Defective
### Answers

<!--chapter:end:08_Week_8.Rmd-->


# Week 9 {}  

Placeholder


## Introduction to Probability Distributions and Revision
## Discrete example (guessing homework answers)
## Generate a homework attempt
## Changing the probability (TRUE/FALSE)
## Studying the distribution
## Cumulative Probability (Advanced)
## Revision Practice Rmd. Solutions
### Provide descriptive statistics for age and memory score variables
### Descriptives by groups
### Visualise
### Visualise a subset
### Variable by a group
### Create a new variable using mutate()
### Subset observations using filter()
### Sort via arrange() 
### Let's do some specific count() using filter() 
## Extra Probability Practice
### TRUE/FALSE questions
### Count the occurencies
### Plot
### Use dbinom() to study the probability
### Less than five or more than five?

<!--chapter:end:09_Week_9.Rmd-->

```{r, echo=FALSE}
HIDDEN_SOLS=FALSE
```

# Week 10: Lab test {}  

This week there is a Lab test.

<!--chapter:end:10_Week_10.Rmd-->


# Sampling distributions {#chap-sampling-distributions}

Placeholder


#### Instructions {-}
#### Learning outcomes {-}
#### Reading {-}
## Recap
## Population vs sample {#population-sample}
#### Statistical inference {-}
## Population parameter vs sample statistic {#parameter-statistic}
#### Parameter vs statistic {-}
## Sampling distributions {#sec-sampling-distributions}
#### Sampling distribution {-}
#### Centre and shape of a sampling distribution {-}
## The standard error of a statistic {#standard-error}
#### Standard error {-}
## The effect of sample size on the sampling distribution {#sample-size-standard-error}
## Take-home message
## Lab: Hollywood movies
## Summary
## Glossary
## References

<!--chapter:end:11_Sampling_distributions.Rmd-->

```{r, echo=FALSE}
HIDDEN_SOLS=FALSE
set.seed(987)
```

# Bootstrapping and Confidence Intervals  

<div class="lo">
#### Learning outcomes {-}

**LO1.** Understand how bootstrap resampling with replacement can be used to approximate a sampling distribution.

**LO2.** Understand how the bootstrap distribution can be used to derive a range of highly plausible values (a *confidence interval*).

#### Reading {-}
This week's reading is [Chapter 8](https://moderndive.com/8-confidence-intervals.html) of the book by Chester Ismay and Albert Y. Kim. *Statistical Inference via Data Science: A ModernDive into R and the Tidyverse*. Chapman and Hall/CRC, 2019. Freely available online at: https://moderndive.com/
</div>

## Recap

Last week, we learnt about how we can take a *statistic* from a sample to draw conclusions about a *parameter* of the population from which the sample is drawn. 
We then focused on how these sample statistics will vary from sample to sample. We saw that by taking lots of samples we could create a *sampling distribution* for a statistic, allowing us to quantify the variation in the sample statistics due to sampling. Specifically, we learnt that the standard deviation of the sampling distribution is known as the *standard error*. 
Finally, we saw how the size of our samples influences the sampling variation, with bigger samples leading to narrower sampling distributions, and more precise estimates.  

This week, we are going to continue to think about how we can quantify sampling variation, but specifically when we have only a single sample (which is often the case in real life). We will also see how, just as we can take a sample in order to calculate a single point estimate of a population parameter, we can use sampling variation to construct a *range of plausible values* which, in the case of uncertain estimates, might be more meaningful than a single value. 

## From Sampling to Resampling  

We mentioned last week that we often have neither the time nor the resources to collect data from the entire population (a *census*). It is also often infeasible to get *many samples* of size $n$ in order to get an idea of how accurate our estimate of the population parameter is. 

**How can we study the variability of our sample statistic with only one sample?** 

It turns out that we can mimick the act of sampling $n$ units from the population, by *resampling with replacement* $n$ units from our original sample of $n$ units. This is broadly known as **bootstrapping**.

<div class="def">
#### Bootstrapping {-}
**Bootstrap definition:** Random sampling *with replacement* from the original sample, *using the same sample size.*
</div>

`r msmbstyle::question_begin(header="&#x25BA; The NFL Example")`
Think back to last week. We saw a dataset of **all** the National Football League players at the beginning of 2015, along with their yearly salaries. 

This was our **population** (in real life we often don't have data on the entire population). 

We took multiple samples of 50 players in order to study how the mean salaries of those samples varied (this allowed us to determine the accuracy of using a mean from a sample of 50 players ($\bar{x}$) as an estimate of the population parameter $\mu$). 
In fact, we took 2000 samples of 50 players, which is not at all feasible in practice.  

Now let's imagine we only collect one sample of 50 players. 
We can approximate the sampling distribution of $\bar{x}$ (the mean salary of our sample) by *bootstrapping*. 
To do this, we:

1. Collect a sample of 50 players.
1. Compute the mean salary of the sample.
1. Take a random sample *with replacement* of 50 players *from our original sample* (this is known as a **resample**), and compute the mean of the resample. 
1. Re-do point 3 many times. 

<div class="red">
#### Think {-}  

What do we mean by **with replacement**, and why is it necessary?
`r msmbstyle::solution_begin(header = "&#x25BA; Answer", hidden=FALSE)`
**With replacement** simply means that as we take our sample, we replace the first item before we choose the second.. and so on.  
If we resampled our 50 player sample *without* replacement, we would simply end up with the same 50 players, and therefore the same mean!
`r msmbstyle::solution_end()`
</div>

`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden=FALSE, toggle=FALSE)`
1. Take a sample. We have a sample of 50 players and their salaries, which we can read in to R as follows:  
```{r message=FALSE}
library(tidyverse)
library(moderndive)

nfl_sample <- read_csv("data/nfl_sample.csv")

nfl_sample
```

2. Compute the mean salary of our sample:
```{r}
nfl_sample %>%
  summarise(avg_salary = mean(YearlySalary))
```

3. Sample our original sample, with replacement, and compute the mean:
```{r}
nfl_resample1 <- nfl_sample %>%
  rep_sample_n(size = 50, replace = TRUE)

nfl_resample1

nfl_resample1 %>% 
  summarise(avg_salary = mean(YearlySalary))
```

4. and again..
```{r}
nfl_resample2 <- nfl_sample %>%
  rep_sample_n(size = 50, replace = TRUE)

nfl_resample2

nfl_resample2 %>% 
  summarise(avg_salary = mean(YearlySalary))
```
and so on...  
`r msmbstyle::solution_end()`

<div class="red">
##### Key point {-}  

If we resample with replacement from our original sample enough times, then the distribution of all the means of these *resamples* begins to approximate the sampling distribution. 
</div>

We can speed up this process by getting R to take many resamples for us, in the same way that last week we asked it to take many samples from a population.
```{r}
nfl_2000resamples <- nfl_sample %>% 
  rep_sample_n(size = 50, replace = TRUE, reps = 2000)
```
The above line of code takes 2000 sample of size 50, by sampling with replacement from our original sample of size 50. $2000 \times 50 = 100,000$, so this results in a tibble with $100,000$ rows.  
```{r}
nfl_2000resamples
```

We can compute the mean of each of the 2000 *resamples* drawn from the original sample (just like last week when we computed the mean of each of 2000 samples drawn from the population).
```{r}
nfl_resample_means <- nfl_2000resamples %>%
  group_by(replicate) %>%
  summarise(avg_salary = mean(YearlySalary))
```

and we can plot them:
```{r fig.cap="Bootstrap resampling distribution based on 2000 resamples"}
ggplot(nfl_resample_means, aes(x = avg_salary)) + 
  geom_histogram(color = "white") + 
  labs(x = "resample mean")
```

`r msmbstyle::question_begin()`
Where do you think that this histogram is centred?

+ the mean salary of the population ($\mu$)
+ the mean salary of the original sample ($\bar{x}$)
+ somewhere else
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden=FALSE)`
The distribution of means of resamples will be centred around the **mean of our original sample, 2.11**
```{r}
nfl_resample_means %>%
  summarise(mean_of_means = mean(avg_salary))
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Last week we looked at the **standard error** (the standard deviation of the sampling distribution). 
We have seen how the boostrap distribution is an approximation of the sampling distribution. 

TRUE or FALSE: The standard deviation of the bootstrap distribution is an approximation of the standard error of $\bar{x}$.
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
TRUE!
`r msmbstyle::solution_end()`


## More generally...

Now let's think more generally about what we did there... 

1. We were interested in estimating some unknown parameter of a population.
1. We had a sample of size $n$ drawn at random from the population.
1. We took 1000 *resamples* (of size $n$) from our original sample, and calculated a statistic for each one. 
1. We then visualised the distribution of those statistics. 

The tool below will help to conceptualise these steps:

+ **The big blue distribution at the top**: The population  
+ **The vertical blue line**: population parameter $\mu$
+ **The yellow sample button**: Take a sample from the population (note you can change the sample $n$)
+ **The green resample button**: Samples with replacement from the original sample (the yellow one), and calculates the mean (which is then dropped into the bottom panel)
+ **The bottom panel**: The distribution of resample means - the bootstrap distribution!

Spend 10 minutes changing things such as the sample size. If you have any questions about what is happening, then ask one of the tutors. 
`r knitr::include_url("http://wise1.cgu.edu/vis/bootstrap", height="650px")`
**source: [http://wise1.cgu.edu/portfolio/bootstrap](http://wise1.cgu.edu/portfolio/bootstrap)**

## Confidence Intervals

`r msmbstyle::question_begin()`
Look at the bootstrap distribution below. Roughly, between what two values do most of the resample means lie?
```{r echo=FALSE}
ggplot(nfl_resample_means, aes(x = avg_salary)) + 
  geom_histogram(color = "white") + 
  labs(x = "resample mean")
```
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=FALSE)`
"Most" is very vague. Just eyeballing, most of the distribution lies between 1.5 and 2.7. 
```{r fig.cap="Bootstrap resampling distribution based on 2000 resamples"}
ggplot(nfl_resample_means, aes(x = avg_salary)) + 
  geom_histogram(color = "white") + 
  labs(x = "resample mean") +
  geom_vline(xintercept = c(1.5, 2.7))
```
`r msmbstyle::solution_end()`

Confidence intervals simply answer more exactly where "most" sample means lie - they give us a **range of plausible values** for our population parameter. 

To construct a confidence interval, we need two things:  

1. a confidence level;  
1. a measure of sampling variability.  

We have the latter, in the form of our bootstrap distribution.  
The confidence level, instead, needs to be set by us.
For instance, we might ask between which values the middle 95% (or 90%, or 80%, etc.) of our distribution falls. 
In other words, the confidence level is the "success rate": the proportion of all samples whose intervals contain the true parameter.

<div class="def">
#### How exactly do we interpret a confidence interval?

If we were to do this whole process over and over again: 

+ take a random sample of size $n$
+ sample with replacement from that sample
+ construct a 95% confidence interval

If we did this many many times, then about 95% of the confidence intervals we created would contain the population mean.  

So if we did this 100 times, we would expect about 5 of our 95% confidence intervals to not contain the true population mean. 

And if we had been constructing 80% confidence intervals instead, we would expect roughly 80 of them to contain the population mean.  
```{r eval=FALSE, echo=FALSE}
#nfl <- read_tsv('https://edin.ac/2TexAFA')
mu=mean(nfl$YearlySalary)

ci_100 <-
  nfl %>% rep_sample_n(size = 50, reps=100) %>%
  nest_legacy() %>%
  mutate(
    bs = map(data, ~rep_sample_n(., 50, replace = TRUE, reps=1000)),
    bs_sts = map(bs, ~summarise(., stat=mean(YearlySalary))),
    bs_ci = map(bs_sts, ~infer::get_confidence_interval(., level = 0.95, type = "percentile"))
  ) %>% select(replicate, bs_ci) %>%
  unnest_legacy() %>%
  mutate(containspop = ifelse(`2.5%`<= mu & `97.5%` >= mu, "in","out"))

ggplot(ci_100, aes(xmin=`2.5%`,xmax=`97.5%`, y=replicate))+
  geom_errorbarh(aes(col=containspop))+
  geom_vline(xintercept=mean(nfl$YearlySalary), col="red")
```
</div>

### Calculating confidence intervals using a bootstrap standard error

We can construct confidence intervals using the **standard error**. 
However, we *can not* compute standard errors from just one sample, so we need to estimate the standard error of a statistic using bootstrap. 

We also use the following rules of thumb: 

<div class="red">
##### If the distribution is symettric and bell-shaped... {-}
+ 68% of values will lie within 1 standard deviation of the mean.
+ 95% of values will lie within 1.96 standard deviations of the mean.
+ 99.7% of values will lie within 3 standard deviations of the mean.
</div>

We have our sample mean, and we can calculate the standard deviation of our bootstrap distribution (to approximate the standard error of the sample mean).
We therefore have all the information we need to calculate, for instance, a 95% confidence interval - it is simply $1.96 \times \text{standard error}$ above and below our mean. 

Formally, we can write this 95% interval as:   
  
<center>$\text{Statistic} \pm 1.96 \times SE$</center>  
  
  
And in R...
```{r}
#recall that our original sample mean was 2.11496
original_sample_mean <- 2.11496

nfl_resample_means %>%
  summarise(
    sd_of_means = sd(avg_salary), 
    ci_lower = original_sample_mean - (1.96 * sd_of_means),
    ci_upper = original_sample_mean + (1.96 * sd_of_means)
  )
```


## Summary

Let's recap what we've done today:

1. We started with a sample from a population.
1. We calculated a statistic from our sample to estimate a parameter in our population.
1. We used bootstrap (random sampling with replacement from our original sample) to estimate the standard error of the statistic.  
1. We constructed a range of plausible values by combining the sample statistic and the bootstrap estimate of the standard error of the statistic. 

We constructed our bootstrap distribution using code like below:
```{r}
bootstrap_distribution <- 
  nfl_sample %>%
  rep_sample_n(50, replace = TRUE, reps = 2000) %>%
  group_by(replicate) %>%
  summarise(avg = mean(YearlySalary))
```

and we used the standard deviation of our bootstrap resample means... 
```{r}
bootstrap_distribution %>%
  summarise(sd_of_means = sd(avg))
```
to calculate some 95% confidence intervals using the formula:  
$\bar{x} \pm 1.96 \times SE$  
which became:  
$2.11 \pm 1.96 \times 0.3$  
giving us a confidence interval of $[1.52, 2.70]$.  

<div class="red">
##### Stop and think {-}

What we did today entailed **specifying** what variable we were interested in, **generating** replicates, **calculating** the statistic for each replicate, and finally, we **visualised** the distribution. This is an important framework for understanding how to estimate sampling variation to evaluate the accuracy of our statistical inferences. The steps for this are visualised in Figure \@ref(fig:bootstrap-pipeline) below.  
```{r bootstrap-pipeline, echo=FALSE, fig.align='center', out.width='75%', fig.cap='Pipeline of bootstrapping-based inference'}
knitr::include_graphics('images/visualize.png')
```
**source: [https://moderndive.com/8-confidence-intervals.html](https://moderndive.com/8-confidence-intervals.html)**
</div>


## Take-home message

Using just one sample, it is possible to quantify estimation error by taking repeated resamples with replacement from our original sample. 
We can use this to construct ranges of plausible values of the parameter we are estimating. 

__This teaches us a standardised way of reporting uncertainty in our estimates.__



## Lab 

The following code chunk reads in a sample of the Hollywood movies data we saw last week. 
```{r, message=FALSE}
hollywood_sample <- read_tsv('https://edin.ac/2N9yHms') %>% 
  select(Movie, Genre, RottenTomatoes) %>%
  na.omit %>%
  sample_n(size=25)
```

`r msmbstyle::question_begin()`
This week, we're interested in the average Rotten Tomatoes rating for all Hollywood movies between 2007 and 2013.   
What is our best estimate of this with the data we just read in?
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
$\bar{x}$: The mean Rotten Tomatoes rating for our sample.
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Calculate the sample statistic
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
hollywood_sample %>% 
  summarise(avg_rating = mean(RottenTomatoes))
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Generate 1000 bootstrap resamples to create the bootstrap distribution. 
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
bootstrap_distribution <- hollywood_sample %>%
  rep_sample_n(25, replace = TRUE, reps = 1000) %>%
  group_by(replicate) %>%
  summarise(avg_rating = mean(RottenTomatoes))
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Estimate the standard error of the sample statistic from your bootstrap distribution.
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
bootstrap_distribution %>%
  summarise(estimated_SE = sd(avg_rating))
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Compute the 95% confidence intervals around our estimate of the average Rotten Tomatoes rating, and plot the bootstrap distribution and the confidence interval.
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
samplemean <- hollywood_sample %>% 
  summarise(avg_rating = mean(RottenTomatoes)) %>%
  pull(avg_rating)

se <- bootstrap_distribution %>%
  summarise(estimated_SE = sd(avg_rating)) %>%
  pull(estimated_SE)

ci_lower <- samplemean - 1.96 * se
ci_upper <- samplemean + 1.96 * se

ggplot(bootstrap_distribution, aes(x=avg_rating)) +
  geom_histogram() +
  geom_vline(xintercept = c(ci_lower, ci_upper)) +
  labs(x = "bootstrap avg rating")
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Go back to the top where we read in the data, and change the sample you are collecting from 25 to 50. Run the previous tasks again - how has the confidence interval changed?
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r message=FALSE}
hollywood_sample <- read_tsv('https://edin.ac/2N9yHms') %>% 
  select(Movie, Genre, RottenTomatoes) %>%
  na.omit %>%
  sample_n(size=50)

bootstrap_distribution <- hollywood_sample %>%
  rep_sample_n(50, replace = TRUE, reps = 1000) %>%
  group_by(replicate) %>%
  summarise(avg_rating = mean(RottenTomatoes))

samplemean <- hollywood_sample %>% 
  summarise(avg_rating = mean(RottenTomatoes)) %>%
  pull(avg_rating)

se <- bootstrap_distribution %>%
  summarise(estimated_SE = sd(avg_rating)) %>%
  pull(estimated_SE)

ci_lower <- samplemean - 1.96 * se
ci_upper <- samplemean + 1.96 * se

ggplot(bootstrap_distribution, aes(x=avg_rating)) +
  geom_histogram() +
  geom_vline(xintercept = c(ci_lower, ci_upper)) +
  labs(x = "bootstrap avg rating")
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
Look back to last week. What was the **population** mean yearly salary for all NFL players at the beginning of 2015? 
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
2.238 (million dollers!)
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin(header="&#x25BA; A bigger Question")`
A researcher lives in Boston. They want to estimate salaries of NFL players, and in 2015 they go around and ask 50 players about their yearly salaries.  
The code below reads in the sample they collected.
```{r}
nflboston <- read_csv("nflboston.csv")
```
Compute the sample mean, and calculate 99% confidence intervals via bootstrap standard error
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
```{r}
samplemean <- nflboston %>% summarise(avg = mean(YearlySalary))

bootstrap_distribution <- nflboston %>%
  rep_sample_n(50, replace = TRUE, reps = 1000) %>%
  group_by(replicate) %>%
  summarise(avg_salary = mean(YearlySalary))

samplemean <- nflboston %>% 
  summarise(avg_salary = mean(YearlySalary)) %>%
  pull(avg_salary)

se <- bootstrap_distribution %>%
  summarise(estimated_SE = sd(avg_salary)) %>%
  pull(estimated_SE)

ci_lower <- samplemean - 3 * se
ci_upper <- samplemean + 3 * se

ggplot(bootstrap_distribution, aes(x=avg_salary)) +
  geom_histogram() +
  geom_vline(xintercept = c(ci_lower, ci_upper)) +
  labs(x = "bootstrap avg salary")
```
`r msmbstyle::solution_end()`

`r msmbstyle::question_begin()`
This confidence does not include the population mean. Why not?  

*hint:* Look at your data, and think about what you know about how it was collected - why might this not be a good sample?
`r msmbstyle::question_end()`
`r msmbstyle::solution_begin(hidden=HIDDEN_SOLS)`
The researcher, living in Boston, seems to have sampled a lot of players from the New England Patriots (a local team).  

The key thing here is that the statistical inference we are making (that the sample mean is an estimate of the population mean) **assumes** that the sample is an unbiased representation. In this case it is not a truly random sample!
`r msmbstyle::solution_end()`
```{r}
samplemean <- nflboston %>% summarise(avg = mean(YearlySalary))

bootstrap_distribution <- nflboston %>%
  rep_sample_n(50, replace = TRUE, reps = 1000) %>%
  group_by(replicate) %>%
  summarise(avg_salary = mean(YearlySalary))

samplemean <- nflboston %>% 
  summarise(avg_salary = mean(YearlySalary)) %>%
  pull(avg_salary)

se <- bootstrap_distribution %>%
  summarise(estimated_SE = sd(avg_salary)) %>%
  pull(estimated_SE)

ci_lower <- samplemean - 3 * se
ci_upper <- samplemean + 3 * se

ggplot(bootstrap_distribution, aes(x=avg_salary)) +
  geom_histogram() +
  geom_vline(xintercept = c(ci_lower, ci_upper)) +
  labs(x = "bootstrap avg salary")
```

## Glossary

- *Population.* The entire collection of units of interest.
- *Sample.* A subset of the entire population.
- *Parameter.* A fixed but typically unknown quantity describing the population.
- *Statistic.* A quantity computed on a sample.
- *Sampling distribution.* The distribution of the values that a statistic takes on different samples of the same size and from the same population.
- *Standard error.* The standard error of a statistic is the standard deviation of the sampling distribution of the statistic.

- *Resample.* To sample again from your original sample
- *Bootstrapping.* Repeated random sampling with replacement
- *Bootstrap distribution.* The distribution of statistics calculated on random **re**samples. Approximates the sampling distribution of the sample statistic.
- *Confidence interval (CI).* A range of plausible values around an estimate (e.g., a sample statistic), taking into account uncertainty in the statistic (e.g., sampling variability)
- *Confidence level.* The percentage of confidence intervals which will contain the true population parameter **in the long run** (i.e., if you sampled the population and constructed confidence intervals many times over). The proportion of all samples whose intervals contain the true parameter.

## References

- Chester Ismay and Albert Y. Kim. *Statistical Inference via Data Science: A ModernDive into R and the Tidyverse*. Chapman and Hall/CRC, 2019. Freely available online at: https://moderndive.com/

<!--chapter:end:12_bootstrap_confints.Rmd-->

