```{r, echo=FALSE}
HIDDEN_SOLS=FALSE
TOGGLE=TRUE
set.seed(15732)
ggplot2::theme_set(ggplot2::theme_gray(base_size=13))
```

```{r}
knitr::opts_chunk$set(fig.align='center', message=FALSE, out.width = '90%')
```

# Chi-square tests {#chap-chi-square}


<div class="lo">
#### Instructions {-}
  
- This week's lab consists of a walkthrough, showing a worked example, followed by a series of questions for you to attempt.
- The Rmarkdown file for this week is [here](https://uoe-psychology.github.io/uoe_psystats/dapr1/labsheets/week_19_practice.Rmd).


#### Learning outcomes {-}

By the end of this lab, you should be able to:

**LO1.** Understand when to use goodness-of-fit and tests of independence.

**LO2.** Check the validity conditions.

**LO3.** Report the test results.

</div>



## Recap {-}

<font size="1">

| Test type | One-sample | Independent samples | Paired data |
|------------------------|:-------------------------------------------------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------:|
| Null hypothesis | $H_0 : \mu = \mu_0$ | $H_0 : \mu_1 - \mu_2 = 0$ | $H_0 : \mu_d = 0$ |
| Alternative hypothesis | $$ \begin{array}{ll}   i.   & H_1 : \mu < \mu_0 \\   ii.  & H_1 : \mu > \mu_0 \\   iii. & H_1 : \mu \neq \mu_0 \end{array} $$ | $$ \begin{array}{ll}   i.   & H_1 : \mu_1 - \mu_2 < 0 \\   ii.  & H_1 : \mu_1 - \mu_2 > 0 \\   iii. & H_1 : \mu_1 - \mu_2 \neq 0 \end{array} $$ | $$ \begin{array}{ll}   i.   & H_1 : \mu_d < 0 \\   ii.  & H_1 : \mu_d > 0 \\   iii. & H_1 : \mu_d \neq 0 \end{array} $$ |
| Test statistic | $$ t = \frac{\bar x - \mu_0}{SE(\bar x)} $$ | $$ t = \frac{\bar x_1 - \bar x_2}{SE(\bar x_1 - \bar x_2)} $$ | $$ t = \frac{\bar d - 0}{SE(\bar d)} $$ |
| Standard error | $$ SE(\bar x) = \frac{s}{\sqrt{n}} $$ | (a) Unequal population variances  $$ SE(\bar x_1 - \bar x_2) =  \sqrt{  \frac{s_1^2}{n_1} +   \frac{s_2^2}{n_2} } $$   (b) Equal population variances  $$ SE(\bar x_1 - \bar x_2) =  s_p \sqrt{  \frac{1}{n_1} +   \frac{1}{n_2} } $$ | $$ SE(\bar d) = \frac{s_d}{\sqrt{n}} $$ |
| P-value | $$ \begin{array}{ll}   i.   & \Pr(T_{df} \leq t) \\   ii.  & \Pr(T_{df} \geq t) \\   iii. & 2 \times \Pr(T_{df} > |t|) \end{array} $$ | $$ \begin{array}{ll}   i.   & \Pr(T_{df} \leq t) \\   ii.  & \Pr(T_{df} \geq t) \\   iii. & 2 \times \Pr(T_{df} > |t|) \end{array} $$ | $$ \begin{array}{ll}   i.   & \Pr(T_{df} \leq t) \\   ii.  & \Pr(T_{df} \geq t) \\   iii. & 2 \times \Pr(T_{df} > |t|) \end{array}  $$ |

</font>


<br>
Recall that the pooled standard deviation is:
$$
s_p = \sqrt{
\frac{(n_1 - 1 )s_1 ^2 + (n_2 - 1 )s_2 ^2}{n_1 + n_2 - 2}
}
$$


<br>
In the past weeks we focused on tests for:

- a __quantitative__ response variable (Weeks 16 and 18)
- a __quantitative__ response variable and a __categorical + binary__ explanatory variable (Week 17)

This week we will investigate tests for:

- a __categorical__ response variable 
- a __categorical__ response variable and a __categorical__ explanatory variable

For the first time, we will be working with a statistical test that applies to categorical variables with more than two categories.


The two tests we will be applying today are the chi-square goodness-of-fit test and the chi-square test of independence.
The first is used to assess whether sample results conform with an hypothesis about the proportional breakdown of the various categories in the population.
The latter tests if two categorical variables are associated in the population or not.




## Walkthrough: Birthdays of the week

- What day of the week were you born on?
- Are people equally likely to be born on any of the seven days of the week?
- Or are some days more likely to be a person’s birthday than other days?

To investigate this question, days of birth were recorded for the 147 "noted writers of the present" listed in _The World Almanac and Book of Facts 2000_. 


```{r echo=FALSE, include=FALSE}
# Generate data
library(tidyverse)

days = list(
  name = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'),
  times = c(17, 26, 22, 23, 19, 15, 25)
)

writers = tibble(DayOfWeek = rep(days$name, days$times))
writers = sample_n(writers, nrow(writers))

# writers = writers %>%
#   mutate(WriterID = 1:nrow(writers)) %>%
#   select(WriterID, DayOfWeek)

writers

write_tsv(writers, 'data/writers.txt', col_names = TRUE)
```

The data are stored in the file `dob_writers.txt`.



---

`r msmbstyle::question_begin(header = "&#x25BA; Question A.1")`
Identify the observational units and variable here. 

Is the variable categorical or quantitative? If it is categorical, is it also binary? 

- Observational units: 

- Variable: 

- Type: 
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
- Observational units: The 147 noted writers of the present listed in _World Almanac and Book of Facts 2000_

- Variable: Day of the week on which the birthday falls

- Type: Categorical
`r msmbstyle::solution_end()`



---




`r msmbstyle::question_begin(header = "&#x25BA; Question A.2")`
Read the data into R.

Summarise the data by creating a frequency table of the seven days of the week.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
Let's read the data into R:
```{r}
library(tidyverse)

writers <- read_tsv('data/writers.txt',col_names = TRUE)
```

Inspect the first six rows:
```{r}
head(writers)
```

Check the dimensions of the tibble:
```{r}
dim(writers)
```

Day of the week is encoded as a character rather than a factor (remember that day of the week is categorical). Let's fix the encoding:
```{r}
writers <- writers %>%
  mutate(DayOfWeek = factor(DayOfWeek))

head(writers)
```

Check that the levels of the factor are in the order we expect:
```{r}
levels(writers$DayOfWeek)
```

They are not, so let's fix this:
```{r}
writers <- writers %>%
  mutate(DayOfWeek = factor(DayOfWeek, 
                            levels= c("Monday", "Tuesday", "Wednesday", 
                                      "Thursday", "Friday", "Saturday", "Sunday")))

levels(writers$DayOfWeek)
```

There are many equivalent ways to create a table of counts. One option could be:
```{r}
writers_table <- writers %>% 
  group_by(DayOfWeek) %>% 
  summarise(count = n())

writers_table
```

`r msmbstyle::solution_end()`



---



`r msmbstyle::question_begin(header = "&#x25BA; Question A.3")`
Construct a bar graph of these data which displays proportions on the y-axis.

Comment on what it reveals about whether the seven days of the week are equally likely to be a person’s birthday.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
The following bar graph displays the data:
```{r}
writers_table <- writers_table %>%
  mutate(prop = count / nrow(writers))

writers_table

ggplot(writers_table, aes(x = DayOfWeek, y = prop)) +
  geom_col(fill = 'lightblue') +
  labs(x = 'Day of the week', y = 'Proportion of writers') +
  theme_classic(base_size = 15)
```

There does not appear to be a great difference in the proportion of people born on any given day of the week.
`r msmbstyle::solution_end()`


---

`r msmbstyle::question_begin(header = "&#x25BA; Question A.4")`
Let $p_{Mo}$ represent the proportion of _all_ people who were born on a Monday, or equivalently, the probability that a randomly selected individual was born on a Monday.

Similarly define $p_{Tu},\ p_{We},\ ...,\ p_{Su}$.

Are these parameters or statistics? Explain why.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
The values $p_{Tu},\ p_{We},\ ...,\ p_{Su}$  represent the proportion of all people who were born on Tuesday, Wednesday, ..., and Sunday, respectively.

These values are parameters because they describe the entire population.
`r msmbstyle::solution_end()`



---


`r msmbstyle::question_begin(header = "&#x25BA; Question A.5")`
The null hypothesis says that the seven days of the week are _equally likely_ to be a person’s birthday. 

In that case, what are the values of $p_{Mo},\ p_{Tu},\ ...,\ p_{Su}$?
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
The values of the proportions specified by the null hypothesis are:
$$
\begin{array}{l}
p_{Mo} = 1/7 = .1429 \\
p_{Tu} = 1/7 = .1429 \\
... \\
p_{Su} = 1/7 = .1429
\end{array}
$$
`r msmbstyle::solution_end()`

---

<div class="def">
<br>
The test procedure we are about to apply is called a chi-square goodness-of-fit test. 

It applies to a categorical variable, which need not be binary. 
The null hypothesis asserts specific values for the population proportion in each category. 
The alternative hypothesis simply says that at least one of the population proportions is not as specified in the null hypothesis. 

As always, the test statistic measures how far the observed sample results deviate from what is expected if the null hypothesis is correct. 
With a chi-square test, you construct the test statistic by comparing the observed sample counts in each category to the expected counts under the null hypothesis.
</div>

---


`r msmbstyle::question_begin(header = "&#x25BA; Question A.6")`
Intuitively, what value would make sense for the expected count of Monday birthdays in this study (with a sample size of 147), under the null hypothesis that one-seventh of all birthdays occur on Mondays? Explain why.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
You would expect the frequency of birthdays on a Monday to be $147 \times \frac{1}{7}= 21$.

We would multiply the total sample size by the proportion of birthdays we expect on a Monday.
`r msmbstyle::solution_end()`


---

<div class="def">
<br>
We calculate the __expected count__ for a particular category by multiplying the sample size by the hypothesized population proportion for that category:
<center>
$$
E_i = n \times p_{i0}
$$
</center>

*[Note: the subscript $i$ denotes the particular category, while the subscript $0$ on $p_{i0}$ emphasizes that this is the hypothesized value for $p_i$ in the null hypothesis.]*

</div>

---


`r msmbstyle::question_begin(header = "&#x25BA; Question A.7")`
Calculate the expected counts for each of the seven days. 
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
As in this particular study $p_{Mo} = p_{Tu} = \cdots = p_{Su}$, the expected counts will all be computed as $147(1/7) = 21$.

The sample size is:
```{r}
n <- nrow(writers)
n
```

We multiply the sample size by the hypothesized proportion for each category, 1/7:
```{r}
writers_table <- writers %>%
  group_by(DayOfWeek) %>%
  summarise(observed = n()) %>%
  mutate(expected = rep(n * (1/7), 7))
```

`r msmbstyle::solution_end()`


---

<div class="def">
<br>
How do we measure how far are the observed counts from the expected counts under the null hypothesis?

If you simply subtract the expected counts from the observed counts and then add them up, you will obtain zero:

```{r}
writers_diff <- writers_table %>%
  mutate(diff = observed - expected)
writers_diff

# Check that the sum of (O - E) is zero
writers_diff %>% 
  pull(diff) %>% 
  sum()
```

Instead, we will __square the differences__ between the observed and expected counts, and then add them up.

One issue, however, remains to be solved. 
A squared difference between observed and expected counts of 100 has a different weight in these two scenarios:

__Scenario 1.__ $O = 30$ and $E = 20$ lead to a squared difference $(O - E)^2 = 10^2 = 100$.

__Scenario 2.__ $O = 3000$ and $E = 1990$ lead to a squared difference $(O - E)^2 = 10^2 = 100$.

However, it is clear that a squared difference of 100 in Scenario 1 is much more substantial than a squared difference of 100 in Scenario 2. 
It is for this reason that we divide the squared differences by the the expected counts to "standardize" the squared deviation.

The test-statistic is obtained by adding up the standardized squared deviations,
<center>
$$
\chi^2 = \sum_{i} \frac{(O_i - E_i)^2}{E_i}
$$
</center>
and the sum is over all categories.

**Note:** As $(O - E)^2$ is equal to $(E - O)^2$, you can equivalently write the test-statistic as:
<center>
$$
\chi^2 = \sum_{i} \frac{(O_i - E_i)^2}{E_i} = \sum_{i} \frac{(E_i - O_i)^2}{E_i}.
$$
</center>
</div>

---


`r msmbstyle::question_begin(header = "&#x25BA; Question A.8")`
For each of the seven days of the week, compute $\frac{(O - E)^2}{E}$. 
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
We can compute the standardized squared deviations as follows:
```{r}
writers_table <- writers_table %>%
  mutate(std_sq_diff = (observed - expected)^2/expected)

writers_table
```

`r msmbstyle::solution_end()`

---

`r msmbstyle::question_begin(header = "&#x25BA; Question A.9")`
Add the standardized squared differences up, in order to compute the chi-square test statistic.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
The value of the chi-square test statistic in this sample is:

```{r}
chi_stat <- writers_table %>%
  pull(std_sq_diff) %>%
  sum()

chi_stat
```
`r msmbstyle::solution_end()`


---


`r msmbstyle::question_begin(header = "&#x25BA; Question A.10")`
What would be the value of the chi-square statistic if the observed and expected frequencies had been exactly equal?

Based on this, what kind of values (e.g., large or small) of the test statistic constitute evidence against the null hypothesis that the seven days of the week are equally likely to be a person’s birthday?

Do you think the value calculated in part h provides convincing evidence? If you are not sure, what additional information do you need? Explain your reasoning.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
If the observed and expected frequencies had been exactly equal, the chi-square statistics would have been 0 and you would have had no reason to doubt that all days of the week are equally likely to be someone's birthday.
<center>
$$
\chi^2 = \frac{(21 - 21)^2}{21} + \cdots + \frac{(21 - 21)^2}{21} = 0
$$
</center>


Large values of the test statistic constitute evidence against the null hypothesis. 
Answers will vary about whether this test statistic provides convincing evidence. 
The additional evidence you need is the p-value. 
You need to know how likely it is that you would obtain a test statistic this large (or larger) by random chance alone if all seven days of the week are equally likely to be a person’s birthday.

`r msmbstyle::solution_end()`


---

<div class="def">
<br>
As always, your next step is to calculate the p-value. 

The p-value tells you the probability of getting sample data at least as far from the hypothesized proportions as these data are, by random chance if the null hypothesis is true. 

So again, a small p-value indicates the sample data is unlikely to have occurred by chance alone if the null hypothesis is true, providing evidence in favour of the alternative. 

When the test statistic is large enough to produce a small p-value, then the sample data provide strong evidence against the null hypothesis
</div>

---

`r msmbstyle::question_begin(header = "&#x25BA; Question A.11")`
Calculate the p-value for this test using the function `pchisq(<test statistic>, df)`.

Write a sentence interpreting the p-value meaning in the context of this study about birthdays of the week.

*[Hint: the degrees of freedom are equal to the number of categories minus 1.]*
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
We want the probability to the right of the chi-square test statistic:
```{r}
1 - pchisq(chi_stat, 6)
```

If all seven days of the week are equally likely to be a person’s birthday, the probability that you would obtain a test statistic this large (or larger) by random chance alone is .56.
`r msmbstyle::solution_end()`

---


`r msmbstyle::question_begin(header = "&#x25BA; Question A.12")`
Based on this p-value, what would be your test decision at the $\alpha = .10$ level?

And at the $\alpha = .05$ and $\alpha = .01$ levels?
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`

At the $\alpha = .10$ level, we fail to reject the null hypothesis that all seven days of the week are equally likely to be a person's birthday, as the p-value is larger than the significance level.

The same conclusion would be reached at the other two significance levels.

`r msmbstyle::solution_end()`


---

<div class="def">
<br>
Certain technical conditions must be satisfied for this chi-square procedure to provide accurate p-values. 

In addition to requiring a random sample from the population of interest, __all expected counts need to be at least five__. 

When this condition is not met, one option is to combine similar categories together to force all expected counts to be at least five. 
</div>

---

`r msmbstyle::question_begin(header = "&#x25BA; Question A.13")`
Is the expected counts condition satisfied for this birthday study? 

What about the random sampling condition? 

If not, would you be comfortable in generalizing the results to a larger population anyway? Explain. 
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
Yes, all the expected counts are 21, which is greater than 5. 

However, the random sampling condition is not met. 

These are the birthdays of "noted writers of the present" which is not a random sample of the population of all citizens. 
`r msmbstyle::solution_end()`


---

`r msmbstyle::question_begin(header = "&#x25BA; Question A.14")`
Summarize your conclusion about whether these sample data provide evidence against the null hypothesis that any of the seven days of the week are equally likely to be a person’s birthday.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(toggle = TOGGLE)`
You have no statistical evidence against the null hypothesis that the seven days of the week are all equally likely to be a person’s birthday (at least for the population of famous writers).

We can't generalise this to the population of all citizens for the shortcoming discussed in the previous question.
`r msmbstyle::solution_end()`


---

<div class="lo">
#### Technology detour: The chi-square test using built-in R functions {-}

In R, we can perform a chi-square test using the function 

`chisq.test(<frequency table>, p=<null hypothesis>)`


__Step 1.__ Frequency table and null hypothesis:
```{r}
observed <- writers %>% 
  group_by(DayOfWeek) %>% 
  summarise(observed = n()) %>%
  pull(observed)
observed

probabilities <- rep(1/7, 7)
probabilities
```

__Step 2.__ User the function `chisq.test`:
```{r}
chisq.test(observed, p = probabilities)
```
</div>




## Lab: Joking for a tip

Can telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer?

A [study](https://doi.org/10.1111/j.1559-1816.2002.tb00266.x) published in the Journal of Applied Social Psychology^[Gueaguen, N. (2002). The Effects of a Joke on Tipping When It Is Delivered at the Same Time as the Bill. _Journal of Applied Social Psychology, 32_(9), 1955-1963.] investigated this question at a coffee bar of a famous seaside resort on the west Atlantic coast of France.
The waiter randomly assigned coffee-ordering customers to one of three groups.
When receiving the bill, one group also received a card telling a joke, another group received a card containing an advertisement for a local restaurant, and a third group received no card at all. 

The data are stored in the file `TipJoke.csv`. 
The variables are:

- `Card`: None, Joke, Ad.
- `Tip`: 1 = The customer left a tip, 0 = The customer did not leave tip. 

In the following, we will consider leaving a tip as "success".

---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.1")`
Load the data into R and inspect it.

Pay particular attention to:

- the variable names;
- the dimensions of the tibble;
- the format of the data (i.e., make sure that variables are correctly encoded).
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
Load the data:
```{r}
library(tidyverse)

tipjoke <- read_csv('data/TipJoke.csv', col_names = TRUE)
```

Inspect the first six rows:
```{r}
head(tipjoke)
```

Check the dimensions of the tibble:
```{r}
dim(tipjoke)
```
We have 211 observations on 2 variables.

Make the variables factors and give more meaningful names to the variable `Tip`:
```{r}
tipjoke <- tipjoke %>%
  mutate(Card = factor(Card),
         Tip = factor(Tip, levels = c(0, 1), labels = c('NoTip', 'Tip')))

head(tipjoke)
```

`r msmbstyle::solution_end()`

---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.2")`
Identify the observational units in this study.

Identify the explanatory and response variables in this study, and classify them as either categorical (also binary) or quantitative.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
- Observational units: The 211 adults ordering coffee at the bar of the seaside resort on the west coast of France.

- Explanatory variable: Type of card (if any) given to the customer.
Type: Categorical but not binary as it has three categories.

- Response variable: Whether or not the customer let a tip.
Type: Categorical and binary.
`r msmbstyle::solution_end()`

---


`r msmbstyle::question_begin(header = "&#x25BA; Question B.3")`
Create a barplot that visually summarises the data.

Comment on what the graph reveals.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
```{r}
ggplot(tipjoke, aes(x = Card, fill = Tip)) +
  geom_bar()
```

From the stacked bar graph, it appears that perhaps the joke card does produce a higher success rate, but we need to investigate whether the differences are statistically significant.
`r msmbstyle::solution_end()`


---


`r msmbstyle::question_begin(header = "&#x25BA; Question B.4")`
Create a two-way table showing how many customers left or not a tip for each type of card (including none given).
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
In R, we can construct a two-way table using the function `table()`:
```{r}
observed <- table(tipjoke$Tip, tipjoke$Card)
observed
```
`r msmbstyle::solution_end()`


---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.5")`
State, in words, the null and alternative hypotheses of this study.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
- The null hypothesis asserts that whether a customer left a tip or not is independent of the type of card given.
- The alternative hypothesis says that the two variables are associated (or related).
`r msmbstyle::solution_end()`

---


`r msmbstyle::question_begin(header = "&#x25BA; Question B.6")`
Which test would you use to test the hypotheses stated in the previous question?
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
We need to use a chi-square test of independence.
`r msmbstyle::solution_end()`


---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.7")`
Compute the value of the test statistic and corresponding $p$-value.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
```{r}
ind_test <- chisq.test(observed)
ind_test
```

The chi-square statistic in the sample is $\chi^2 = 9.953$.

The $p$-value is $\Pr(\chi^2(2) \geq 9.953) = 0.007$.

`r msmbstyle::solution_end()`


---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.8")`
Inspect the expected frequencies.

Look at the pearson residuals and comment on what you notice.

*[Hint: If `out <- chisq.test(<table>)`, the expected counts can be obtained as `out$expected` and the Pearson residuals as `out$residuals`.]*
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
The output of `chisq.test` returns many objects:
```{r}
names(ind_test)
```

We are interested in the `expected` frequencies:
```{r}
ind_test$expected
```

Recall the observed frequencies:
```{r}
observed
```

More customers than expected under the null hypothesis:
- tipped after receiving a joke card
- didn't tip after receiving an advertising card
- didn't tip after receiving no card

Less customers than expected under the null hypothesis:
- tipped after receiving an advertising card
- didn't tip after receiving a joke card
- tipped after receiving no card


The Pearson residuals are:
```{r}
ind_test$residuals
```

The top three contributions to the chi-square statistic is due to:
- more customers than expected under the null hypothesis tipped after receiving a joke card
- less customers than expected under the null hypothesis tipped after receiving an advertisement card
- less customers than expected under the null hypothesis didn't tip after receiving a joke card
`r msmbstyle::solution_end()`


---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.9")`
Check that the assumptions of the test are satisfied. These are the conditions required for the test to be valid.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
Assumptions checks:

- A simple random sample is taken from a large population.
- Each outcome can be classified into one cell according to its category on one variable (type of card) and its category on the second variable (whether a tip was given or not).
- The expected frequency in each cell is 5 or greater.

Hence, the conditions required for the test results to be valid are met.

`r msmbstyle::solution_end()`

---

`r msmbstyle::question_begin(header = "&#x25BA; Question B.10")`
Write your conclusion linked to the test results and in the context of the problem.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin(hidden = HIDDEN_SOLS, toggle = TOGGLE)`
A chi-square test of independence between tipping and card type was performed ($\chi^2(2) = 9.953$, $p = .007$). 
The chi-square test shows that the tip rate differs depending on the which card (Joke, Ad, or None) the waiter gave to the customer. 
To understand the nature of this difference in the chi-square test, we need to compare observed and expected frequencies. 
The observed number of tips in the joke group (30) is quite a bit higher than expected (20.47), while the observed counts for both the advertising and no card groups are lower than expected. 
`r msmbstyle::solution_end()`
